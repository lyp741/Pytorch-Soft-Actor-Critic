{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txtyJlCt0Rly",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from collections import namedtuple, deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!killall 9-swarm.x86_64\n",
    "from mlagents.envs import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnI3nIje0Rl4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vv8Kx-8x0Rl7"
   },
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uf6gPWP80Rl8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4X3jRQD0Rl-"
   },
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGDk4qTZ0Rl_",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity, batch_size):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.batch_size = batch_size\n",
    "        self.position = 0\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self):\n",
    "        batch = random.sample(self.buffer, self.batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KieKl4E0RmB",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class NormalizedActions(gym.ActionWrapper):\n",
    "    def _action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low) / (high - low) - 1\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ReplayBuffer2:\n",
    "    \" Internal memory of the agent \"\n",
    "    \n",
    "    def __init__(self, buffer_size, batch_size, n_agents=1, seed=0):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        \n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \" Add a new experience to memory \"\n",
    "        for i in range(self.n_agents):\n",
    "            e = self.experience(state[i,:], action[i,:], reward[i], next_state[i,:], done[i])\n",
    "            self.memory.append(e)\n",
    "        \n",
    "    def sample(self):\n",
    "        \" Randomly sample a batch of experiences from the memory \"\n",
    "        \n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float()\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float()\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float()\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float()\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float()\n",
    "#         print(dones.shape)\n",
    "#         dones = done.squeeze(axis = 1)\n",
    "        return states, actions, rewards, next_states, dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        \" Return the current size of internal memory. Overwrites the inherited function len. \"\n",
    "        \n",
    "        return len(self.memory)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynjwRBCl0RmD",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dec_f_go0RmG"
   },
   "source": [
    "<h1>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1801.01290\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPAkyjg80RmH",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, 400)\n",
    "        self.linear2 = nn.Linear(400, 300)\n",
    "        self.linear3 = nn.Linear(300, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, 400)\n",
    "        self.linear2 = nn.Linear(400, 300)\n",
    "        self.linear3 = nn.Linear(300, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, 400)\n",
    "        self.linear2 = nn.Linear(400, 300)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(300, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(300, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(mean, std)\n",
    "        z = normal.rsample()\n",
    "        action = torch.tanh(z)\n",
    "        \n",
    "        log_prob = normal.log_prob(z) - torch.log(1 - action.pow(2) + epsilon)\n",
    "        log_prob = log_prob.sum(-1, keepdim=True)\n",
    "        \n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(mean, std)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(z)\n",
    "#         action = mean\n",
    "        action  = action.detach().cpu().numpy()\n",
    "#         print(action)\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdT8llxi0RmJ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def soft_q_update(batch_size, \n",
    "           gamma=0.99,\n",
    "           mean_lambda=1e-3,\n",
    "           std_lambda=1e-3,\n",
    "           z_lambda=0.0,\n",
    "           soft_tau=1e-2,\n",
    "          ):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample()\n",
    "\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    expected_q_value = soft_q_net(state, action)\n",
    "    expected_value   = value_net(state)\n",
    "    new_action, log_prob, z, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "\n",
    "    target_value = target_value_net(next_state)\n",
    "    next_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss = soft_q_criterion(expected_q_value, next_q_value.detach())\n",
    "\n",
    "    expected_new_q_value = soft_q_net(state, new_action)\n",
    "    next_value = expected_new_q_value - log_prob\n",
    "    value_loss = value_criterion(expected_value, next_value.detach())\n",
    "\n",
    "    log_prob_target = expected_new_q_value - expected_value\n",
    "    policy_loss = (log_prob * (log_prob - log_prob_target).detach()).mean()\n",
    "#     print(policy_loss.item(),log_prob[0],expected_new_q_value[0])\n",
    "\n",
    "    mean_loss = mean_lambda * mean.pow(2).mean()\n",
    "    std_loss  = std_lambda  * log_std.pow(2).mean()\n",
    "    z_loss    = z_lambda    * z.pow(2).sum(1).mean()\n",
    "\n",
    "    policy_loss += mean_loss + std_loss + z_loss\n",
    "\n",
    "    soft_q_optimizer.zero_grad()\n",
    "    q_value_loss.backward()\n",
    "    soft_q_optimizer.step()\n",
    "\n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )\n",
    "    return policy_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_q_update1(batch_size):\n",
    "    gamma=0.99\n",
    "    soft_tau=1e-2\n",
    "    alpha = 0.2\n",
    "    mean_lambda=1e-3\n",
    "    std_lambda=1e-3\n",
    "    z_lambda=0.0\n",
    "    state, action, reward, next_state, done = replay_buffer.sample()\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).to(device)\n",
    "    new_action, log_prob, z, mean, log_std = policy_net.evaluate(state)\n",
    "    v_target = target_value_net(next_state)\n",
    "    q1 = soft_q_net(state, action)\n",
    "    q2 = soft_q2_net(state, action)\n",
    "    v = value_net(state)\n",
    "    q_bak = (reward + (1 - done) * gamma * v_target).detach()\n",
    "    q1_pi = soft_q_net(state, new_action)\n",
    "    q2_pi = soft_q2_net(state, new_action)\n",
    "    min_q_pi = torch.min(q1_pi, q2_pi)\n",
    "    \n",
    "    v_bak = (min_q_pi - alpha*log_prob).detach()\n",
    "    pi_loss = (alpha*log_prob - min_q_pi).mean()\n",
    "    q1_loss = 0.5*F.mse_loss(q1,q_bak)\n",
    "    q2_loss = 0.5*F.mse_loss(q2,q_bak)\n",
    "    v_loss = 0.5*F.mse_loss(v,v_bak)\n",
    "    \n",
    "    \n",
    "    log_prob_target = q1_pi - v\n",
    "    policy_loss = (log_prob * (log_prob - log_prob_target).detach()).mean()\n",
    "\n",
    "    mean_loss = mean_lambda * mean.pow(2).mean()\n",
    "    std_loss  = std_lambda  * log_std.pow(2).mean()\n",
    "    z_loss    = z_lambda    * z.pow(2).sum(1).mean()\n",
    "    \n",
    "    policy_loss += mean_loss + std_loss + z_loss\n",
    "    policy_optimizer.zero_grad()\n",
    "    pi_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    soft_q_optimizer.zero_grad()\n",
    "    q1_loss.backward()\n",
    "    soft_q_optimizer.step()\n",
    "    soft_q2_optimizer.zero_grad()\n",
    "    q2_loss.backward()\n",
    "    soft_q2_optimizer.step()\n",
    "    value_optimizer.zero_grad()\n",
    "    v_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )\n",
    "    return v_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_q_update2(batch_size):\n",
    "    gamma=0.99\n",
    "    soft_tau=1e-2\n",
    "    alpha = 0.2\n",
    "    mean_lambda=1e-3\n",
    "    std_lambda=1e-3\n",
    "    z_lambda=0.0\n",
    "    state, action, reward, next_state, done = replay_buffer.sample()\n",
    "    state      = torch.FloatTensor(state).squeeze(1).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).squeeze(1).to(device)\n",
    "    action     = torch.FloatTensor(action).squeeze(1).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).to(device)\n",
    "#     print(state.shape, action.shape, next_state.shape, done.shape)\n",
    "#     print(1 - done)\n",
    "    with torch.no_grad():\n",
    "        v_target = target_value_net(next_state)\n",
    "        next_q_value = reward + (1 - done) * gamma * (v_target)\n",
    "#         print('next q: ',next_q_value)\n",
    "    q1 = soft_q_net(state, action)\n",
    "    q1_loss = F.mse_loss(q1, next_q_value)\n",
    "    q2 = soft_q2_net(state, action)\n",
    "    q2_loss = F.mse_loss(q2, next_q_value)\n",
    "    new_action, log_prob, z, mean, log_std = policy_net.evaluate(state)\n",
    "    q1_pi = soft_q_net(state, new_action)\n",
    "    q2_pi = soft_q2_net(state, new_action)\n",
    "    min_q_pi = torch.min(q1_pi,q2_pi)\n",
    "    policy_loss = ((alpha * log_prob) - min_q_pi).mean()\n",
    "#     reg_loss = 0.001 * (mean.pow(2).mean() + log_std.pow(2).mean())\n",
    "#     policy_loss += reg_loss\n",
    "    \n",
    "    vf = value_net(state)\n",
    "    with torch.no_grad():\n",
    "        vf_target = min_q_pi - (alpha * log_prob)\n",
    "    \n",
    "    vf_loss = F.mse_loss(vf, vf_target)\n",
    "    \n",
    "    \n",
    "#     log_prob_target = q1_pi - vf\n",
    "#     policy_loss = (log_prob * (log_prob - log_prob_target).detach()).mean()\n",
    "\n",
    "#     mean_loss = mean_lambda * mean.pow(2).mean()\n",
    "#     std_loss  = std_lambda  * log_std.pow(2).mean()\n",
    "#     z_loss    = z_lambda    * z.pow(2).sum(1).mean()\n",
    "    \n",
    "#     policy_loss += mean_loss + std_loss + z_loss\n",
    "\n",
    "    soft_q_optimizer.zero_grad()\n",
    "    q1_loss.backward()\n",
    "    soft_q_optimizer.step()\n",
    "    soft_q2_optimizer.zero_grad()\n",
    "    q2_loss.backward()\n",
    "    soft_q2_optimizer.step()\n",
    "    value_optimizer.zero_grad()\n",
    "    vf_loss.backward()\n",
    "    value_optimizer.step()\n",
    "    \n",
    "\n",
    "    \n",
    "#     soft_q2_optimizer.zero_grad()\n",
    "#     q2_loss.backward()\n",
    "#     soft_q2_optimizer.step()\n",
    "    \n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )\n",
    "    return policy_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mlagents.envs import UnityEnvironment\n",
    "import numpy as np\n",
    "env = NormalizedActions(gym.make(\"Pendulum-v0\"))\n",
    "# env = UnityEnvironment(file_name = \\\n",
    "#                        '/home/ohk/Downloads/ContinuousControl-D4PG-master/Reacher_Linux/9-swarm.x86_64',\n",
    "#                       no_graphics=False,base_port=10001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "# brain_name = env.brain_names[0]\n",
    "# brain = env.brains[brain_name]\n",
    "# print(brain_name)\n",
    "# print(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # reset the environment\n",
    "# print('reset the environment')\n",
    "# env_info = env.reset(train_mode=True)[brain_name]\n",
    "# print('finished reset')\n",
    "# # number of agents\n",
    "# num_agents = len(env_info.agents)\n",
    "# print('Number of agents:', num_agents)\n",
    "\n",
    "# # size of each action\n",
    "# action_dim = brain.vector_action_space_size[0]\n",
    "# print('Size of each action:', action_dim)\n",
    "\n",
    "# # examine the state space \n",
    "# states = env_info.vector_observations\n",
    "# state_dim = states.shape[1] #ndarray\n",
    "# print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], states.shape))\n",
    "# print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.reset()\n",
    "num_agents = 1\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "finished = False\n",
    "if( finished ):\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0shUhdEW0RmR",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "max_frames  = 40000\n",
    "max_steps   = 500\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "batch_size  = 128\n",
    "p_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aMEanpTP0RmM",
    "outputId": "676b2cb4-eca8-4729-fdad-428b033e1e0e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "hidden_dim = 256\n",
    "\n",
    "value_net        = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "target_value_net = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "\n",
    "soft_q_net = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "soft_q2_net = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion = nn.MSELoss()\n",
    "\n",
    "value_lr  = 1e-2\n",
    "\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer = optim.Adam(soft_q_net.parameters(), lr=value_lr)\n",
    "soft_q2_optimizer = optim.Adam(soft_q2_net.parameters(), lr=value_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=value_lr)\n",
    "\n",
    "\n",
    "replay_buffer_size = 1000000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5smGTbtX0RmS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "max_frames  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHA_aYX90RmV",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# while frame_idx < max_frames:\n",
    "#     state = env.reset()\n",
    "#     episode_reward = 0\n",
    "#     \n",
    "#     for step in range(max_steps):\n",
    "#         action = policy_net.get_action(state)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "# #         env.render()\n",
    "#         replay_buffer.push(state, action, reward, next_state, done)\n",
    "#         if len(replay_buffer) > batch_size:\n",
    "#             l = soft_q_update(batch_size)\n",
    "#             p_l.append(l)\n",
    "#         \n",
    "#         state = next_state\n",
    "#         episode_reward += reward\n",
    "#         frame_idx += 1\n",
    "#         \n",
    "#         if frame_idx % 1000 == 0:\n",
    "# #             plot(frame_idx, rewards)\n",
    "#             plot(frame_idx, p_l)\n",
    "#             print(episode_reward)\n",
    "#         if done:\n",
    "#             break\n",
    "#         \n",
    "#     rewards.append(episode_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NormalizedActions<TimeLimit<PendulumEnv<Pendulum-v0>>>>\n"
     ]
    }
   ],
   "source": [
    "print(env)\n",
    "scores = []\n",
    "policy_loss = []\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAE/CAYAAABLrsQiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsvXmYI2d5r32/klpqtaTee7qne3Z7Nm/YnomHHYNNAnES2wQSIOeEL8sHgfCRnGwQcpKQHMjCWYAESEKSL2FJAoGEJSxxGMcLBmOY8djG9nhW27P19HRPS2rt63v+qHrVNT2SWktJqup57+vS1a0qlaq01VPP9nuElBKNRqPRXLl4en0AGo1Go+kt2hBoNBrNFY42BBqNRnOFow2BRqPRXOFoQ6DRaDRXONoQaDQazRWONgQ2I4TYKYQ4JIRICCHe1evj0bSHEOJ9QojP9Po4NJpOog2B/fwWcL+UMiKl/LNeH8xKhBBSCJESQiTN299Y1gkhxJ8KIS6atw8KIYRl/Y1CiINCiLT598ZGt71SEUJsEUJ8XQgRFUKcF0J8VAjhs6z3CiHeL4Q4Z148HBJCDFvWbxNCfNVctyCE+GCdfdX7fN4nhChYPvekEGJbg9sGhBB/KYSYE0IsCiH+TQgxY1n/GSHErBBiSQhxVAjxi5Z11wghDpivPyqE2C+EuMay/jeFEE+ar+9ZIcRvVnlN3xJCxIUQZ4QQv1fjtf+++d2+3bLsqRWvtyiE+DfL+pZ/C5bHvcV8nl9cuc5VSCn1zcYbsB/4xTrrvT0+PglcXWPd24AjwAZgBnga+CVznR94HvhvQAB4l3nfv9q2LRyjrwfviwA8VZa/D/hMG8/7deDvgX5gCvgB8C7L+vcD/wlsNo/hOqDf8p6fAH4NCJnPcUON/az2+dR8HQ1s+1vA48CkeQyfBv7Vsv21QMD8fxdwHthj3h8GtpivzWs+9xOWbX8LuBnwATvN/b7Rsv5p4APmtlcBs8BPrDj+q8z39Rxwe53P9yTws+3+FiyPGQGeAZ6kzm/eDbeeH8Baupk/6BKQBZLADvMk8BfmCSEF3A7cARwCloDTwPssz7HF/IL+nLkuCvwS8EPAE0AM+OiK/f48cNh87D3A5jrHWO/L/x3grZb7vwB81/z/h4GzgLCsPwW8ZrVtG3jf3gd8AfiM+Z78Ioa3+h6ME+FF4J+BUfPxnwR+3fx/xnxN7zDvXw0smj/8EeCrwLz53nwV2GDZ7/3mSebbQMbcdivwAJAAvgl8lPYMwWHgRy33/yfwV+b/I+b35Koa274V+FaD+1nt83lfrdfRwLZ/AXzQsu4O4EiN59qJcbL+qSrrfMAvA+k6r+PPgD+33E8D11jufx747RXbfAP4UeA5ahuCV5jvdajd34Jl2V8C7zC/R642BDo0ZCNSylcB3wLeKaUMSymPmqvejHHCiQAPYRiEn8W4WroDeLsQ4q4VT7cP2A78NPBh4HcwjMi1wE8JIV4BYG73XuB1wIS5/39a5VAfNMMU/yqE2GJZfi3GlZ/icXOZWveENH8BJk+sWF9r20a4E8MYDAP/gHHleBfGD3ga40T+MfOxDwC3mv+/AuNK7xXm/ZdjnDwlhjH5O4yr7U0YJ/uPrtjvf8U44UYwrkb/ETgIjAP/A3iL9cFCiCeEEG9u4nV9BHijEGLADKe8Fvh3c931QBF4vfl5HBVC/LJl2xcCzwkhvmGGhe4XQlxfYz+rfT4AP26Gdp4SQry9iW3/FniJEGJaCDEA/AzGybeCEOLjQog0xhXyLMaFj3V9DOMC6c+BP6r2AszQy8uApyyLPwz8rBCiTwixE3gRhtettnkDkJdSXrK/KrwF+IKUMrVieSu/BYQQtwB7MYyB++m1JVprN1ZcHWB4BJ9aZZsPAx8y/9+CcaUyY1l/Efhpy/1/AX7V/P8bwC9Y1nkwrqI219jXyzFCAcMYJ8UnMUMxGN7MLstjt5vHIoDfBT674rn+AdObqbdtA+/Z+4AHVyw7DNxmub8eKGBcVV6F4Rl5MH6IbwPOmI/7JPBrNfZzIxBd8Vn9oeX+JowTs/Wq8R9pzyPYjWFYiub78ffqPcG4QJAYJ9ogcAOG9/Jqc/1/mK/5teZn9psYRs9fZT+rfT7XYBhUL/BijJP1mxrcdhDj4kKar+MQpne2Yhsv8FLgvwN9VdaHMK6g76jxXv0Bxgk3YFn2YuC45f37A8u6MHAM2Gref44qHgEwgOFp3mrTb8ELHABeVO0378ab9gi6w2nrHSHEPiHEfUKIeSFEHCP0M75imznL/5kq98Pm/5uBjwghYuZVlwqLzFAFKeWDUsq8lDIG/ApGKGS3uTqJ8aNXDAJJaXzbV65T6xMNbNsIp1fc3wx80fK6DmP8OCellCfM/d2IcQX5VeCcecX4CgyPAfMq/K+EEM8LIZaAB4FhIYS3xn6nMQyF9arx+QaPH/PKXSUef0YI4cEI1f0rxklwHCMc9KfmJhnz7x9KKTNSyieAz2KEOdT6h6SU35BS5oH/BYyx/HlZqfv5SCmfllKek1KWpJTfwfBUXt/IthihoX5z3yHz9XxjxeMxn/shjLj626usT2EY7k8JIdZZ1wkh3onhJd8hpcyZy0YxvKc/NPe/EfgRIcQ7zM3+APi0lPLZKu+Hlddh/C4eWHE8rf4W3oHhQT28yn5dgzYE3WHlyfAfga8AG6WUQxg/jlYrbE4Db5NSDltuQfPH3uixqX0/BbzAsu4FLLvpTwE3rKicuGHF+lrbNnocVk4Dr13xuvqllGfN9Q9gnMj85rIHME4kI8Bj5mN+HSNmvU9KOYhxBQiXvtfW/c4CI0KIkGXZpoZfgJSvlUZIMCyl/AdgFOPk9VEpZU5KeREjVKVO9E/UeO1Y1jdqSFf7fC47XC793Ott+wLg76WUi+ZJ+s+BW4QQKy9eFMprq4YH4wrdWnX08xj5oNuklGcsj90GlKSUn5JSFs11VkN5G/AuM7RzHuO9/mchxLtX7PMtGF75au9lo7+F24C7Lft9MfC/hRArw47uodcuyVq7UT009P4Vj7kAvMX8/xbz/mfM+1swvpA+y+PPYHFrMZKq/938/24Ml/Za8/4Q8IYax3YtxlW0F8Oj+DBGZUSfuf6XMK68ZzCujp/i8qqhX8GoLHknl1aW1Ny2gffsfawIv2BUsNyPGeLCyH/caVn/Vgx3/2/N+3eY979mecwHMa5c+zFOyl+0vrcrPytz2Xcxrrz9GGGOpZXH1uT34STGSc6HEYL4IvAPlvUPAn9lvqe7ze/Cbea6nRhhvtvNz+y/YSTPq4WGVvt87sQwksL8zp21fAdX2/bvMMKRQ0AfRk7qrLluHfBG8/vkBX4EIwd2p7n+1cBN5rpBjGTwOZYro34Go8pod5XXNIgRAnwzhgGZAh4GPmCuHzOXqdtp4A1A2PIcGzDCSleteO52fgvDK/b7HYzKrqFen39a/p72+gDW2m3lyYXqhuD15g8tgRHWqFSm0KQhMO//V4zyOVWF9P/XOLZXmV/2FMYJ50vAdst6gXHyXDRvH+TSSpKbMOLdGeBR4KYmtk0CL6txXO/jckPgMX9cR8z36QTwR5b1O8336S3m/SHzB/9uy2Omzc8jCRzFyCWsZgi2YSTck1SpGjJPCD/TxPfhRnM/UWABo+plnWX9DEb4I4lhNN62YvvXYcTIl8znuday7hvAexv8fP4JI9eUxEjovmvFfuptO4aRM7iAcWJ+CLjFXDeB4Y3FzGP8AfD/WrZ9g7m/JEb+4+tYSmCBZzHyIEnL7S9XfGe/D8QxDMZfAwM13uvnWJEjAH6bKpVXtPlbqPebd+NNJa00Go1Gc4WicwQajUZzhaMNgUaj0VzhaEOg0Wg0VzjaEGg0Gs0VjjYEGo1Gc4XjW/0hzmZ8fFxu2bKl14eh0Wg0juPgwYMLUsqJ1R7nekOwZcsWDhw40OvD0Gg0GschhGhIIkWHhjQajeYKRxsCjUajucLRhkCj0WiucLQh0Gg0miscbQg0Go3mCkcbAo1Go7nC0YZAo9FornC0IdBoNJorHG0INBqN5gpHGwKNRqNxKN89eZEvP3Z29Qe2iTYEGo1G41C+cPAMH/z3Ix3fjzYEmqZ46NgChVK514eh6SELyRyf+/6pXh/GFUEyWyQc6LwknDYEmoY5MZ/kv/ztI/zHU3O9PhRND/nSobO8+19+wNxStteHsuZJ5AqE+7Uh0DiIC0s5AM7rE8AVTTSdB2A+kevxkax9tEegcRwx8wRwMalPAFcy8UwBgHn9Peg4iVyRiPYINE4iZp4ALibzPT4STS+JZ4qA9gi6QTKrDYHGYaiQwMWUPgFcySiPYEF7BB0noUNDGqcRT6sTgPYIrmQqoSHtEXSUYqlMplAi0t/X8X1pQ6BpGO0RaACWMvqCoBukciUA7RFonEUsrXMEGosh0B5BR1nKGu+zLh/VOAplCNL5Eul8scdHo+kFUkpdNdQlkjnjNxbRHoHGScQyy56A9gquTNL5EsWyBHSyuNNUDIHOEWicRDRdYF0kAOiTQKfJ5Evc89R5pJS9PpRLUN7AzHCQWLpAvqjlRjpFMmsYAh0a0jgGKSXxdIGr14UB7RF0mg/e8wxv+/RBDs8men0ol6AMwbaJEKALBzpJJUegQ0Map5DOl8iXylw1YRoCfQLoGMcvJPn0w88D8Mz5pR4fzaUoQ6C+B7qEtHOo0NCg9gg0TkGVjiqPQJcOdo4PfO1pgn1e/F4PR+ac6REsfw+0IegUOjSkcRyqYmhqqJ+Q36tDQx3i/iMXuO/IPO+6bTvbJkIcPe9MQ6A8goWE/h50ikS2iEdAsM/b8X1pQ6BpCGUIhoN9jIUDOjTUAQqlMu//2mG2jA3wlhdvYedUhKNzyV4f1iWoHoKr1hk5Al1C2jmSOUNeQgjR8X1pQ6BpCFU6OhLyMxb2a4+gA/zjI6c4fiHJ79xxDX6fhx2TEc7GMiTMpKETiGcKCAHjoQCRfp/OEXSQRLbYldJR0IZA0yBRq0cQCujYsM3E0nk+tP8oL7l6jNt3rwNg52QEgGMXnOMVxDMFIgEfHo9gIhzQHkEHSeYKXVEeBW0INA0SN5PFQwN9jIf9XExpj8BOPrz/GEuZAr/7Y9dUQgE7pwxD4KQ8QTxTYGjAuEodDwe0zEQH6ZbyKGhDoGmQaLrAgN9LwOdlLOxnMZWnXHZWs5NbOX4hwae/+zxvumUTu6YGK8tnhoME+7yOqhyKZwoMBQ1DMBHRHkEnSXZpKA1oQ6BpkFi6wMiAH4CxUIBSeVlzRtMeH/jaYQb6vPzaq3dcstzjEeyYDHPUoYZgPOzXHkEHSWaLhHWOQOMkYul85QQwFjYMgq4cah9ruehYOHDZ+h2TEY6cd1aOwOoRLGWL5IqlHh/V2mRJh4Y0TiOWKTASWo4Ng24qa5eV5aLV2DkVYSGZc8yc6KVM0eIR6O9BJ9HJYo3jiKbzDAfN0JDyCPQJoC1WlotWY4dZOeSEfgIpJUuZAoMrDYEOD9lOoVQmWyh3RYIatCHQNEgsXWB44NITgA4NtU61ctFqVCqHHJAnyBbK5EvlS0JDoPWGOkEq1z15CdCGQNMA5bIkls5XksUjA36E0CGBdqhWLlqNdZEAQ8E+R1QOqeKASmhIS5J3jITSGdIegcYpJHJFypKKR+D1CEYH/I6JW7uNWuWi1RBCsHMywjEnGgIzRKg9AvtRhkB3FmscQ1x1FZseAaBlJtqgVrloLXZMhTlyPtHzITUrDUHA52Ww36c9gg6wPJ1MewQah6AkqIeDy1cnYyEtPNcKq5WLVmPHZISlbJG5pd6+3ysNAeimsk6R6OJQGtCGQNMAMfMEoMpHQXsErdBIuWg1VOVQr/ME1QyBITOhvwd2k9TJYo3TiCmdoeByaGg8rIXnmqWRctFqVEpIe6w5VNUQRPT3oBMs5whcYAiEEG8QQjwlhCgLIfauWPfbQojjQogjQogfsSx/jbnsuBDiPZblW4UQjwghjgkhPieE8KNxBGoWwciANTTkZylb1MPLG6TRctFqjIb8TEQCjvEIrAnMiXBAJ4s7QCVHEHBHsvhJ4HXAg9aFQohrgDcC1wKvAT4uhPAKIbzAx4DXAtcAbzIfC/CnwIeklNuBKPALbR6bxiaiFY/AGhoy4tuLWoW0IRotF63FzslIz3sJlkwJaq9n+fgnIgESuSLZgpaZsJNEtoDXI+jv607Qpq29SCkPSymPVFl1J/BZKWVOSvkscBy4xbwdl1KelFLmgc8Cdwrjl/Eq4Avm9p8E7mrn2DT2EUsbre4+7/LXRXUX67DA6jy3kGq4XLQWO0xD0EvF17ilq1gxEdZNZZ0gmTWUR7sxnQw6lyOYAU5b7p8xl9VaPgbEpJTFFcs1DiCWzld6CBTjFeE5+z2CVK7Ie/7liTXjbRw6HaVUlvzcS7a0/Bw7p8JkC2VOR9P2HViTWAXnFOMRfUHQCRK57gnOQQOGQAixXwjxZJXbnfU2q7JMtrC81jG9VQhxQAhxYH5+vv4L0LRN1CJBrRgLdU5n5sDzUT77/dN869ja+GxVddVEpL/l56hUDvUwYVzNEEyEjdekPQJ76eZQGoBV9ySlvL2F5z0DbLTc3wCcM/+vtnwBGBZC+EyvwPr4asf0CeATAHv37tXTUTpMrMoJoJNS1OfjGQBOL/bu6tdOouk8Xo9gsI0KkO2WsZU/fK1dR9YcS5kCV02EL1m27BGsDe/NKajQULfoVGjoK8AbhRABIcRWYDvwPeD7wHazQsiPkVD+ijRaJu8DXm9u/xbgyx06Nk2TWHWGFOGAD7/P05FegnOxLACnFzO2P3cvWEwVTH2m1uO94YCPmeGg4zyCimeoQ0O2Ykwn607FELRfPnq3EOIM8CLga0KIewCklE8B/ww8Dfw78MtSypJ5tf9O4B7gMPDP5mMB3g38mhDiOEbO4G/bOTaNfRjTyS79UgohGA/5O3IlOKs8gh7Gw+0kmsozGmr/R71zqreVQ9Z5xQq/z8PwQJ8ODdlMsss5grb2JKX8IvDFGus+AHygyvKvA1+vsvwkRlWRxkGUypKlbIGhgcvbOsbCnZGZmI2bHsEaMQSLVTyqVtgxGeFbx+YplMr0ebvbC5otlMgVy5d5BKCbCztBIlvoWlcx6M5izSosZQpIyWUeAXROZkIZgnOxLMWS+xvWDI+gfUOwcypMoSR5biFlw1E1x5LZTLayfBR0U1knSKyRHIFmjVARnKtmCEIB26WopZTMxjJEAj5KZVkxCm4mms4zYoMh6KXmUDV5CYWWmbCXfLFMrti96WSgDYFmFZTg3HCV0MZ42M9CKm+rPHIiVySVL7Fnywjg/vBQuSyJpguM2WAIrpoI4xG90RyqZwi0R2AvFcE5bQg0TiFWRYJaMRb2ky+WK19cO5g1K4Zu2ToKwBmXVw4tZQuUytKWHEF/n5ct4yEHegR+UvkSmbyWmbCDpJpO5paqIc3aZ1lwrkqy2CwdtDNPoCqGbt40gtcjXO8RqO5oO3IEoDSHuj/Ivq4hCOsSUjtJ5JS4n/YINA4hWplOVt0jAHubylROYOPoAOuH+jnl8qYylWOxI0cARp7guYuprou81Q0NmbOLL+jwkC0oj0DnCDSOIZbOIwQMVnFTl68EbfQIYhmEMIa2bxwZcH138WLKOIGO2hAaAsMQSAnHL3TXK1CGoFp39IT2CGylMrheewQapxBLG92kHs/lXbEVj8DW0FCWdZEAfV4PG0eDnI66O0cQTSmPwJ54784pQ+Kh241l8UyBkN97iQKtQnkEOmFsD8vzinWOQOMQonWaoZZzBPaGhqaGggBsHBlgPpFztdb9ohkaUu9Vu2weC+H3erqeMK4mL6FQ+Q/tEdhDQlcNaZxGPFOomh8AQ15gsN9nqxT1uXiG6SFD0XLj6AAAZ1ycMF5M5env8xD0e215vj6vh20Toa6XkC5VmUVgPaYRLTNhG2pwvU4WaxxDNJ2vWjqqsFNeQErJ+XiW9cojGDX+ull8bjGVty0/oDA0h7qfI6jlEYARHtIegT0ks0V8HkGgibnW7aINgaYusSqzCKzYKTOxlCmSzpdYv8IjcHMJaTRlT1exlR2TEc7GMpUrx26wlCnWNQTGBYGWorYDQ3m0e9PJQBsCzSrE0pcrTloZC9knPHfO7CFYP2wYgolwgP4+j6srhxbT9ugMWdlpSk100ytoxCPQoSF7SGaLXa0YAm0INHUolIyu4W55BOfNHgIVGhJCsGFkwNWhoWjKHuVRKzunlCHoXp5gNUOgFUjtYylbJBzoXsUQaEOgqUOsTjOZYiwcYDGdp2TDUPWKRzC0PNJx40jQ1aGhRZuUR63MDAcZ8Hu7NqQmXyyTKZRW9QjS+RIpG+VGrlSSuUJXE8WgDYGmDvGMUh6tfSIbD/uRcrmDth3Ox7N4zGYyxcZR9zaVFUpllrJF2w2BxyPYvi7cNY+g0lVc54JAy0zYRzJX7GpXMWhDoKlDRV6izpWgnXpD52JZJgf7L2la2jgywFK2SDzdvcSoXdgtL2Flx2T3ppXVk5dQjJvNhTpP0D4JnSPQOIlKV+wqOQKwp6lsNp5hyhIWAksJqQvDQ1Gb5SWs7JyKsJDM2z4PohrxOkNpFKq7WHsE7ZPMdndMJWhDoKnD8iyC1a8EF2xoKjsfzzJtJooVG0bMElIXhocWbZaXsLKji5VDSw14BEpvaF6XkLZNosuD60EbAk0dYnWmkynskpmQUnIunrkkUQzu7iVQoSG7cwTQ3cqhRkJDoyE/QujQULvkiiXyxbJOFmucQyxdwOcRdd3UoWAfXo9oOyQQSxfIFsqXhYaGgn0M9vtcWUJamUXQgdDQukiAoWBfVzSHGjEEPq+H0QG/Dg21SWUojQ4NaZxCNG3oDNXrcPR4BKOh9nsJ1ByC6eHgZes2jg640yNIrV511SpCCGNITRdKSBsxBKCbyuxgWXlUGwKNQ4hn8g2dxMZC/rblBdRkspUeAeDauQQXU3ki/T78HdKM2TEV5shcwtaZ0dWIZwoM+L30VZGgtqKbytonoT0CjdOIpgp1S0cV4+H2ZSbOKY9gqJpHEORMNNPxE57dRDsgL2Fl52SERLbI+aVsx/YBhiGoNphoJeNhv/YI2qQXQ2lAGwJNHWKZQmMegQ0yE+fjGbweUSlDtLJxdIBcsey6k8xiB+QlrGw3K4c63WG8mryEQimQus1gO4lKaEhLTGicQiydr1sxpBgLBdquGpqNZZmMBPBWmYTm1sqhTnsEyyWkzjAE4+EA2UKZVN69g4R6TbIHg+tBGwJNHQwJ6gYMQdhPKl8i08YJ4Fw8w/oqiWIwcgTgvrkE0VR9Ce92GQ35mYgEOHK+s70E9YbSWNEjK9snqUNDGieRLZTIFEoNhYZUU1k7eQJjIM3liWKADSNqQI27PAJDcK6zLv7OyQjHLnTWI1hqwiMA3V3cDks6WaxxEo0ojyra1RuSUjJbxxD093lZFwm4KjSUyRuGtBM6Q1aU5lDZBvXXWjSTIwDtEbRDMlfE7/XQ32fPaNNG0YZAU5WYUh4NNpYshtY9gmi6QK5YrswhqMbG0QFOucgjWB5a31lDsHMqTLZQ7piRLJSMmL/2CLpDL4bSgDYEmhoowbRGcgTLJ4DWPIJzMSP2Pz1c3SMAcy6Bi3IEjQj22cGODlcOLesMrX5yGg358WiZibZIZAtdDwuBNgSaGqhZBPU06BXLCqStGQLVVTy1ikcwG89QKJVb2ke3qchLdNgj2N7hyqFGZhEovB7BaEg3lbVDMtd95VHQhkBTAzWLoJEr2gG/jwG/t+US0vNmV/F0jRwBGJVDZWmUmbqBTs4isBIO+NgwEuRIh1RIG5WXUBhNZVqBtFUS2WLXS0dBGwJNDZpJFoPZVNaiFPW5eBafR1RCTNXY4LK5BJ0UnFvJjg5qDjVrCCYiAea1R9AyyZw2BBoHEUvn8fs8BBusXhhrIyQwG8swOdiPp0ozmWKjy+YSRFN5PKL+MBe72DEZ4cR8knzR/rBZ04YgHGBB5whaJtGDoTSgDYGmBqqZrJ7yqJXxNmQmZuPZuoliMAbaez3CPR5B2hDsq9YpbTc7p8IUy5LnLqZsf+6lBqaTWRk3PQItM9EayR4MpQFtCDQ1iKbzDZWOKsZCrQvPzcazdRPFYOjdTw/3u6ZyyGgm63xYCDpbOdSKR5AvlkmYmjma5tDloxpHYQjONX5looTnmr0SLJelOaKyvkcAphy1WzyCVL4r+QGAqybCeAQc60DlUDxToL/PQ8DXWIhwPKKH2LdKtlAiXyrr0JDGOTQqOKcYCwcoliVLmeauBBfTefKlcs2uYiubRgdc4xFEU4WOzCquRn+fly3joY5MK2tUgloxETY+R50naJ5eDaUBbQg0NYimmxNMWx5i39wJQJWDrhYaAqOXYCGZa0vcrlssdlh5dCU7JyMdGWTfqLyEQnkE7Q4quhJRgnPaEGgcgZSSeLrQUBORolW9ITWZbLVkMSyLz51xeHhISkm0w7MIVrJjMsJzF1NkC/YayWYNwURY6Q25o9/DSSiPINzlWQSgDYGmCum8Eats5kS23F3cpEdgdhXX0xlSqLkETtccSuSKFMuyux7BVAQp4fgFe72CpUyxKUMwYlZKaY+geZayRmJe5wg0jiBmVoo0MqZSMVYJDTV3AjgXz9DnFQ2Js7mll2Ax2R2dISs7JsOA/ZVDzXoEHo9gNGTPyMrvP7fIb3z+8SumFFWHhjSOQgmmNTKLQKEqZJr1CM7Hs0wN1W8mU4yH/QT7vJyOOjthrJRHR8PdMwSbx0L4vR7bNYcaHUpjZcKmIfaf+/5pvnDwTNMFCG5FJ4s1jkLVjjdTNeTzehgZ6Gs+RxDLNhQWAhBCsGEk6HiPINpFeQlFn9fDtgl7K4dKZUki11xoCJabytrl0Kko0N7AIzeR6NFQGmjTEAgh3iCEeEoIURZC7LUsf7UQ4qAQ4gfm31dZ1u0xlx8XQvyZMFtXhRCjQohvCiGOmX9H2jk2TetUBNOaPJGNhZtvKjsXzzRUOqrYODrgfI+gS8qjK9k5Za/m0FKTzWQKO2Qm4ukCJ+aNTmn1fVzrVJLFLvQIngReBzy4YvkC8ONSyuuBtwCftqyiRWMyAAAgAElEQVT7C+CtwHbz9hpz+XuAe6WU24F7zfuaHhBLNz6LwMpYyM9CE8qT5bJkbqlxjwCMuQRnFtOOjht3S3l0JTsmI5yLZytJx3ZptqtYMR7xs9BCc6GVQ6ejlf9blS5xG4lsEb+v8eY9O2nLEEgpD0spj1RZfkhKec68+xTQL4QICCHWA4NSyoel8S35FHCX+bg7gU+a/3/SslzTZWLpxmcRWBkPB5rqI1hI5SiUZEOlo4qNowMkcsXKScqJLKYK+L0eQv7u/qC3jYcAOHXRntBZq4ZgIhwgXyq3Fds/dCpW+f/K8QgKRHoQFoLu5Ah+EjgkpcwBM8AZy7oz5jKASSnlLID5d10Xjk1ThVi6wIDf2/SVyViTwnOVZrLBxg3BhkrlkHPDQ9FUnpFQ44J9djFj9lmcjdnz3jQzlMZKZXZxG3mCQ6djbB4zPuvFlHONvp0keqQzBA0YAiHEfiHEk1Vudzaw7bXAnwJvU4uqPKxp/1EI8VYhxAEhxIH5+flmN9esQjRdaKp0VDEWChDPFBqWQ1Y9BNPDTYSGXDCX4GIqz2io9myFTqHex3N2G4JmQ0Ph9obYl8uSx05FefFVY/T3eVi8QpLFyR4NpQFYda9SyttbeWIhxAbgi8DPSilPmIvPABssD9sAqBDSnBBivZRy1gwhXahzTJ8APgGwd+9e5waLXUo8k2+qdFShegmi6TyTDVzlq67iqSaTxeDsXoJoOs9ol3SGrIyF/AR8np4bAuURtFpCenIhyVK2yE2bRnjw6MKV4xH0aEwldCg0JIQYBr4G/LaU8ttquRnySQghXmhWC/0s8GVz9VcwEsuYf7+MpidE080pjyoqekMNngDOx7P4fZ6GmskUg/19DA/0Odoj6La8hEIIwcxw0P7QUJc9gkfN/MDNm4YZCfVdMR6BMZSm+xcQ0H756N1CiDPAi4CvCSHuMVe9E7ga+F0hxGPmTcX83w78DXAcOAF8w1z+J8CrhRDHgFeb9zU9IJpu7UQ2Fm5Ob+hcPMv6of6mY+kbR5ytQtptwTkr08NBzto013kpU8Dv89Df4JQ6xXCwD59HtOwRHDoVY7Dfx7bxMKOhAIvpK8MjSOYKzg0N1UNK+UWM8M/K5e8H3l9jmwPAdVWWXwRua+d4NPbQrOCcQl3ZN9pLMBvLNJUoVmwcDfLMbGdm9LZLsVQmnmlOudVOZoaD/OeRmlHVpmhWXkLh8QjGwv42DEGUGzeNGHIVA308u2C/qqoT6WWOQHcWay5BSkksU2i6hwCa9wiMEZWNJ4oVG0cGOBPNUC47Lz0UzxSQsvvNZIrp4SDziZwtKqTGLILWTkwTkUBLoaFkrsjRuQQ3bRwGYDQUIHoF5AiklCTXWo5A414SuSKlsmxqTKVisN+H3+tpSHmyVGkma94j2DA6QL5U5oIDh5/0qplMoXoyzsfbDw+16hGA2VPSQiPYE6djlCXctEkZgj6SuSK5ovNnULRDrlimUJLOLR/VXFnEUs3rDCmEEGYvweon6IVkjmJZtmQINo44t4RUeUPNJMDtxM5egqVse4agFY/g0GkjUXzTRkNhRhnUte4VJCrKoy5MFmvWHrFM88qjVsbCfi42IEXdzByClTi5hLRVnSa7mBm2zxC04xFMRAzdqWbDd4dORblqIlTJUSmDutikvLnbqCiP6tCQxglEW9QZUoyFAg15BLPmiWp9E/ISCnWyc2LlkKp571WOYGqoHyHsaSqLp9vzCAol2ZQUiJSSR0/FuGnTst6kMqhr3hD0UHkUtCHQrEDpDLXjETQSGz7XhkfQ3+dlcjDgyNBQtPL+9cbFD/i8TIQDnG1TobXcogS1opWmslOLaRZT+Up+AJabFBfXuN5QQk0n0zkCjRNQyqOtnsjGTSnq1ZQnz8czBHyelj0Po5fAeYZgMZUn5Pc2XXtvJ9PDQc7F2zMEiWwRKWl6KI1CNRc2ozekhOZUfgAsHoEN8w2cTKKHQ2lAGwLNCiqGoMUTwFjIT7ZQJp2vX+VxziwdbVWYbeOoUULqNAzBud6EhRQzI0HOtdlU1mpXsWKihe7iQ6eiDPi97JyKVJYND/gRgjXfVFYZU+nGzmLN2iOazhMJ+PB5W/tqNNpL0GozmWLjSJDZeIZCqTGBu27Ry65ihZKZaKfPom1DUAkNNR7SefRUjBdsGMZrGVvq9QiGg2tfZkKHhjSOIpbOM9yGYNryEPv6P9zz8WxLiWLFhtEBytI+pU27WEz13hBMD/WTL5Ybqt6qRbuGYCjYR59XNOwRZPIlDs8uXZIfUIyG/Gu+fLQynUwnizVOIJYptNRMphgPre4RlMqSuUSupR4CxaZRZ84lWEzluzqruBoz5syGdkpIW51FoBBCmE1ljRmCJ8/FKZblJRVDitGQf81XDSVyRQI+D35fb07J2hBoLqFV5VGF8gjqlZDOJ3KUyrKliiGF6iU45bCEsRNyBKq7uB1vqV2PAJprKlOD6qt5BCMDa98Q9FJnCLQhWBNkCyXe/9Wnbamiiadbm0WgGK0Iz9X+4aqKlmZGVK5karCfPq9wVAlptlAilS/1PDS0Ydgwkr02BBORxj2CR5+PsWl0oCJhbWUs7L8Cykd7pzME2hCsCf7PN4/yNw89y1ceP7f6g1chmm5NcE7R3+clEvDVPQEsj6hs3SPwegTTw0FHlZDGKs14vTUEg0EfIb+3raqqeKZAn1cQbKMMdrxBBVKjkSxa1RsA4/2MpvKrliS7mWSu2DN5CdCGwPUcfD7K33zrJACHZ5faeq5SWbKUbW1MpZXVZhfP2uARgNlL4KASUhW+6MV0MitCGEayXY9gKNje3GUlPLda9dJsPMuFRI6bq+QHwPAyi2XJklliuRZJao9A0yrZQonf/MLjrB8K8qJtYzxzvj2N/iVTQrmd0BAYJaT1ZhLMxrME+7xthR3AmEtwxkEegTIEvfYIwOwlaKOpbClTYLDNK9SJSIBS2ZA1r0elkayGRzB6BegNLWULPSsdBW0IXM2H9h/l5HyKP/nJ69m7ZYRnF1Jt6dCrH+xIm1e0Y6HVPYJWJpOtZMPIABdTeVI5Z1wpqji2Spj3kunhYFsyE/FMoeWuYkWjIysfPRUl4POwa2qw6vorwRAYoSFtCDRNcuhUlL9+8CRvumUjL9s+wa6pQUplyfELrU9zqujktFE+CoZHUDdH0GYPgUJVDjmlwzjqJI9gOEg0XSCdb81ItiNBrWhUb+jQqSjXzwzVLJ28YgyBDg1pmsEICT3B1GA/7/3R3QDsWm+05bcTHoq3qTOkGA8b5X6lGrHh2Vi2rdJRRWUugUPCQ4upPEK0V2ljF0qhtVWpiXYkqBWNeAS5Yoknzy1x8+bq+QFYNqzRNWoIpJRGjkB7BJpm+Mi9xzh+Icmf/OQNlUqDLWMhAj4Pz7SRMI62qTyqGAv5KctlJVMrxVKZC4nWJpOtpDKXwCElpNF0nqFgX8vyHHYy3eZcAjsMQSMeweHZBPliuTKashprXYE0WyhTLEvCPdIZAm0IXMdjp2P81QMneOMPbeTlOyYqy70ewY7JSFseQbuzCBQVvaEqV3AXEjnKsjX56cv2E/IT7PM6prvYCV3FCjWprJXKoXJZsmSDIVCjS+spkD76vGokq+0RBPu8BHyeNRsaSuSM353OEWgaIlso8Zuff5zJwX7ee8fuy9bvmorwzPnWPYJ42ghttFvPXNEbqnICUKWjduQIhBBsHA06yiPodVexYjISwCNoKWGczBcpy/ZDXIbMhL9uaOjQ6Rjrh/qZquMhCiEYW8MyExXlUW0INI3wZ/ce49iFJH/8uuurlvbtWj/IQjLf0qxYMDyCoWDfJeqPrTBeR4F0eURl+4YAnDWX4GIy74hEMYDP62FqsL8lj0DliuzIdRjdxbVP4IdORWv2D1gZWcOGINHj6WSgDYFrePx0jL984AQ/tXcDt+5cV/Uxu6dUwrg1r8AQnGv/x6/mzFbTG1JdxXaEhsDIE5xeTDui6zSazvdsaH01ZkaCLeUIlLxEu+WjUF9v6EIiy5lopmb/gJW1LDxXmVesO4s19cgVjcaxdZF+fueOa2o+Tg30eGa2tTxBrE2dIcXwgB+PqJ4jOBfPMOD3MmiTG7xxdIBUvlTJb/QKKSXRVMExoSEwewlaMARLNugMKerpDa3WSGZlLRsC7RFoGuLP7z3O0bkkf/yT19f9cY6FA6yLBFpOGMfaVB5VeD2C0VD12cXn41lbmskUTikhTeVL5EvlnstLWJkeDnI+nq1ZxlsLOwTnFOPhABeTuarHcOhUjD6v4NrpoVWfR+kNrUWSPR5TCdoQOJ4fnInzFw+c4A17NvDKGiEhK7vWD7YcGoqm7Ytxj4UCVUNDakSlXTilhNRJzWSKmeEgxbJsOmfU7iwCKxORAGW5XJps5dCpKNdMDzU033ks5CeRK5IvOmsinR1UppNpj0BTjXyxzG98/nHGw37++4/VDglZ2T0V4dhckmILIxzj6fZLBhXjEX/V0FC7IypXstEhA2qWBeecZQgAzsaaM5J2ewRweQVZsVTmiTPxuv0DVlTIrZpBcTuqakg3lGmq8uf/eYwjcwn++HX1Q0JWdq2PkC+VeXYh1dS+CqUyiVyxox5BoVRmPpljvY0eQTjgY2Sgr+cegWp2clKOQPUSnG2yuzieKeD1CEL+1iWoFeNmKfFKr+SZ8wkyhVJD+QFYLkBYi3mCZK5If5+Hvh42ImpD4FCePBvn4/ef4Cdv3sCrdk02vN3OSUO463CTeYK4TYJzimpS1HNLWaQ0Zuraiaoc6iWL5mt1SkMZLJfoNltCaocEtaJWd/Gh00aiuJHSUVg2sGvRECxliz3tKgZtCByJNST0ew2GhBRXrQvh84impSaUHIRtoaFwgESueIkaquohqNc81AobRwZ6LjynQhajDlAeVUT6+xjs9zXdVGaHvIRiPFJdb+jQqSjj4QAbRhrzDte6R2BXFV2raEPgQD5633GeOW+GhJpM2AV8Xq6aCDddORS1ebpWtR+uMgR2JosBNowaksurDUDpJIupPD6P6KmCZDVmRgZa8gjsOjFFAj4CPs9lFWSPnYpx06bhhr2OtewRJHs8iwC0IXAUUkr+9qFn+dh9x3ndzTNNhYSs7FofacEjsEd5VDFWpbt41jwh2dVVrNg4MkC+VGYu0ZrSph0oeQm7ymLtYma4v+legqVs0ZZmMlAyE5c2lUVTeU4upBrODwAMB/sQYo0aglxvp5OBNgSOIZ0v8q7PPsb/+OrT3L57HX9453UtP9euqUHOxbOVuH8jqNCGbR6B0huyTCqbjWcJB3y2d1A6oXLISYJzVlppKrNDcM7K+IqmsseazA+AIZkxFOxbk4ag14PrQRsCR/DsQoq7P/YdvvbEOX7rNTv5y/+yp60vhppNcKSJ8FBFX8Ymj2A8VMUjMCeT2Y0TmsqMrmLnNJMpZoaDJLJFlrKNXxTYmSMAmFjhERw6FcUj4IYNqzeSWRkd8K9JKepEtreD60Ebgp6z/+k5fuKjD3EhkeWTP38L77j16rbDC7vNkX/NNJZF03m8Nsa4lUdgLSE1JpPZmx8Ao0xSCDjVQ0NwMZVzVA+BYnq4OTlqKaX9hiDiv8QjOHQ6xq6pQQb8zX3XRkNrs7u412MqQRuCnlEqS/73fxzhFz91gC1jIf7t/3spL9s+sfqGDTA5GGB4oI/DTWgOKcE5u2LcA34v/X2eS5rKZuNZ1tvYTKYI+LxMRvp72ksQTRccaQianUuQypcolaXtHoGaWFcuy0qiuFnWogKplNIROQJnlThcIcTSeX7ls4/xwNF5fmrvBv7wzusaarNvFCFE07MJDME5+378hob8cmw4XyyzkMzZMoegGptGBzjToxxBqSyJpZ2ZI1juLm4skW5nV7Fi3JSZuJjKEUsXSOSKTeUHFGMhP4+b+YW1QqZgGN5eewTaEHSZp87F+aXPHGQunuOP7r6eN92ysSOVJrumBvnnA6cplyWeBuYLGIJz9p7Ixi1NZaqZrBM5AjBKSB8+cbEjz70aS5kCZemsrmLFRDhAn1c03Etg5ywC6zEALCTy/OBs44qjKxkJ+Ymm80gpHVed1SpOkJcAHRrqKv9y8Ayv+/h3KBQln3vbC3nzvk0d+0LvmoqQzpcaDpdE04W2R1SuZCwc4KJZNbQ8kMb+HAEYJaTnl7LkiqXVH2wzKoHpxNCQxyNYPxRsODTUKY8AYD6Z49CpGEPBPraOh5p+nrGQn0JJkjDVOtcC6rX0OjSkDUEXyBfL/N6Xn+TXP/84N20a5qvvemndGa12sGu9KTXRYJ4gbtMsAitjoWWPQI2onO5QaGjj6ABSwrkmdXXswInKo1amhxufVGbnUBpFRXgukePRU9GmGsmsqPd3sc7EM7eRcMCYStCGoOPMLWV5019/l089/Dxvffk2PvML+yo/jE6yYzKMEI2XkEbT9kwnszIWDnAxabjy6gQ91SGPYJc5lOf3v/JUJbzRLZyoPGqlmV4CO4fSKJTe0LMLKY5dSLaUH4Dl93ctlZAuzyvW5aNrlky+xF0f+zaHZ5f42Jtv5r0/uhtflxQGB/w+toyFGkoYZwslMoWS7THu8bCfvKlqej6eIdLv65gLfN3MEH/yuut5+MQCd37sIY7OtTacpxWUIXBijgBgw3CQuaUshQakye2cRaAImRVk+w/PIWVr+QFYNgRrqYQ0mev9LALQhqCjPHR8gdl4lo+9+WbuuGF91/dvVA6tfkLsRFwYLN3FiZwxkKZD3oDijbds4rNvfSGpfIm7P/Zt7nnqfEf3p6jkCBwbGgpSlsZ0uNWIZwp4BISbrPGvhxCCCXNynhDwggZnEKxEGYJqcy7cypIDxlSCNgQdZf/Tc0T6fbx0+3hP9r9rapDnLqZI5+sn1+yWl1CMqe7iVJ7ZeMZ21dFq7Nk8yr+986VcPRnhbZ8+yIe+ebTjYnTRVJ5gn5egDfr9naCZXoJ4psBgsK+hSrNmUOHQ7evCDLYYBlmTHoFpCFp9T+xCG4IOUS5L7n1mjlfuXNezgRO71keQEo7OJes+zm7BOYW1u/h8PNuxRPFKpob6+dxbX8jr92zgI/ce422fOVgZB9gJFlPObCZTVLqL440ZArs9Q1guIb1pY+tFEgN+L36fZ001lal5xaFAby8i2jpDCSHeIIR4SghRFkLsrbJ+kxAiKYT4Dcuy1wghjgghjgsh3mNZvlUI8YgQ4pgQ4nNCCOf+shrgsTMxFpJ5br+mNQVRO1AJ1NWUSNUsArsNgboKPBfLspDMd6x0tBr9fV7+5+tv4Pd//Br+85kL3P3x73Byvr5BbBVDedR5OkMKFZJrpJdgKVvoyNWpKiFtNT8AqklxbXUXJ3NFgn3eruUOa9Hu3p8EXgc8WGP9h4BvqDtCCC/wMeC1wDXAm4QQavLKnwIfklJuB6LAL7R5bKsiZedCBvufnsPnEbxihz2yEa2wcWSAAb931TzBskdgr+1VoaanzhmGqBuhIStCCH7uJVv59C/cwsVkjjs/9m3uO3LB9v0spvKOLR0FCPq9jIX8DXUXd8ojUBcF7ZZNjwysLUOQcMAsAmjTEEgpD0spj1RbJ4S4CzgJPGVZfAtwXEp5UkqZBz4L3CmMouJXAV8wH/dJ4K52jq0e0VSeuz/+bT5/4EyndsH+w3Ps2zbakR9Vo3g8gp1TEQ6v4hEsD6Wx91j9PkM6+MmzcYCOJ4tr8eKrxvnKO1/KxpEBfv7vv8/H7z9u60VANJ13dGgIjPBQozmCTnxnX3vdFD//kq1sXxdu63lGQ2tLgdRQHnW5IaiFECIEvBv4gxWrZoDTlvtnzGVjQExKWVyxvNbzv1UIcUAIcWB+fr7p4xse6COayvPFQ2eb3rYRnr+Y4uhcktt39y4spNg1NciRuUTdE18sk8fv9RC0Ue9IMRb2c+yC4ZF0SmeoETaODvAvb38xd1y/ng/++xHe+U+HVk2iN8pi0tkeARhNZY30EiyZyWK72b1+kN/78WvaTkKPrsHQkBOm2q1qCIQQ+4UQT1a53Vlnsz/ACPOsDMpW+xbIOsurIqX8hJRyr5Ry78RE86EXIQR33TTDd5+92FBJXbPsP2yEH5xgCHavjxBLF5hbytV8TCxVYHjAPuVRK+MhQ3AMOqcz1ChBv5c/f9NNvPs1u/j6D2b5yb94uO0ZBvmi0Scx5nCPYGbYGFlZ74KgExLUdrPWDEEiW3RHaEhKebuU8roqty/X2Wwf8EEhxHPArwLvFUK8E+NKf6PlcRuAc8ACMCyE8K1Y3jHuunEGKeErj9vvFex/eo5dU5HK5KxessucTXC4TmNZLGOv8qiV8YhxghwK9jWtP98JhBC8/dar+Lv/54c4E03zEx99qK2LAZVod2ozmWJ6uJ90vlR3al2mUKJQsleC2m5GQ34S2WJDzXFuIJktEgn0/v3uSGhISvkyKeUWKeUW4MPAH0kpPwp8H9huVgj5gTcCX5HGZcp9wOvNp3gLUM/QtM2W8RAv2DjMlw7Za2/i6QLfe27REd4AwM5K5VDthHG0A8qjCtVL0GtvYCW37lzHP/ziPqLpAvc+M9fy8zhZcM7KBrOX4EydyqFONRbaycga6yVI5lziEdRDCHG3EOIM8CLga0KIe+o93swBvBO4BzgM/LOUUiWT3w38mhDiOEbO4G/bObZGuOvGaZ6eXbJVjuD+oxcolWVPy0atDAX7mBkO1pWaiKXztieKFaqXwGmGAOD6mSEmIgG+9+xiy8+x6HDBOUUjk8rcYAjG1pjeUCJb6HlXMbRfNfRFKeUGKWVASjkppfyRKo95n5Tyf1nuf11KuUNKeZWU8gOW5SellLdIKa+WUr5BSlk7qG0TP3bDNF6P4Es2Jo2/+fQcE5EAN8w0N4+1k+yaitT1CGLpAsPBDnkEZtlgJ0ZUtosQglu2jvLIycWWq4iiKePk6XSPYLoyoKaOIejALAK7WUsKpGo62aDbPQK3MxEJ8JKrx/nyY+dskSHIF8s8cGSe23evs71Fvx12TkU4MZ+sqtUvpTQMQYcaosbNE2QnRlTawQu3jnJ+KdvyvOPFSo7AuSdPMK6kAz6P+z2C8NrxCNL5EmXZ+6E0cIUbAjDCQ2djGQ6eirb9XN97dpFEruiY/IBi1/pBimXJiQupy9ZlCiXypfIV6REA7Ns2BsAjLYaH1JWp00NDQghmhoN15zW4wRBUPII1kCNIVobS9P79vuINwY9cO0Wwz2tLeGj/4Tn6+zy85OreiMzVYrdKGFfJE3SqmUxx3cwgd904zct7JLy3GldPhBkZ6OORk60Zgmg6z2C/r2d6Us0wMxLkjMs9AlXdthYMgdK/0h6BAwgFfLz6mkm+9oNZ8sXWS9KklHzz6Tletn3C1kH0drB1PITf66k6pKZTOkOKAb+PD7/xJtY5NDTk8Zh5gmdbm3e8mHJ+V7FiepWRlUuZAkL0flpWPfq8Rrf6Wqgacsp0MtCGAIC7bpomli7w4NHmu5QVz5xPcDaW4dUOCwsB+Lwetk+GOVzVEHRGZ8hN7Ns6xplopuEpXlYMwTl3vHfTw0HmE7mac53jmQKRgM9R+a1qjIb8a2ImgQoNuaKz+ErgZdsnGA35+eJjrYeHvvn0HELAK3ets/HI7GPX1GBVFdJOSVC7iVu2jgLwvRa8gsVU3rEDaVai5hLM1sgTxDMFWyeTdYrRkL8yQ8PNqFkEOjTkEPq8Hu64fj37n55rWbd+/+E5bto4XJnP6jR2r49wIZHjYvLSqtxODaVxE7vXDxLp97WUJ4im3OQRGOG5WuGhpWzR0fkBxciAn4troHw04ZB5xaANQYW7bpomVyxzz1PNd5mej2d54kzcMU1k1VBSEyvzBG5IEHYar0dwy5bRphvLpJRcdFGOYGaVXoJ4pjOzCOxmbI14BImcM8ZUgjYEFW7eNMLG0SBfbiE8pCQKnJgfUOxab1QOrcwTqDGLTktwd5t920Y5uZDiwlLjukOZQolcsewab2pqqB8h6hsCN1wQjJjCc52cJ9INkg6ZVwzaEFQQQnDXjTN8+/gCFxLNiZDtf3qOzWMDXN2m1nonGQ8HGA/7L8sTRNOFjpWOuolbtjbfT6BKGJ2uPKoI+LxMhAM1Q0NuMQSjoT4KJVlJtrqVRLbAgN+L1wHJeW0ILNx54wxlCf/2+GzD26RyRb594iK3757siIyzneyaGrxsWlk8k2fIJVe0neS66UFCfm9T4SElL+GWHAEYCWO3ewSjppCh23sJkjlnDKUBbQgu4ep1Ya6bGWyquexbxxbIF8uO6yauxq6pCEfnEpQschraIzDweT3s2dJcP8Gy8qh73r/pGt3F2UKJfLHckaE0dqPeb7cbgkSu6IiwEGhDcBl33TjDD87GOdHgoPP9h+cYCvaxd0t7s1i7wa71g+SKZZ67uCw1EUt3bhaB29i3dZSjc8mGTzBRlyiPWpkZNjyClfF1NxUNKI/A7QnjZLZI2CHJeW0IVvDjL5hGCPhyA15BqSz5z2cu8MqdE66QGNhVZTZBrIOzCNzGvib7CZTBcEvVEBiGIF8ss7Ci/NJVhsD8vrq9hDSRLThCeRS0IbiMycF+XnLVOF967NyqVQmHTkVZTOUdXTZq5ep1YbweUdEcklISyxQYdsGPvxvcsGGYgM/TcMJ4MZXHI3BFyaWi1lwCVxkCU4HU9R6BDg05mztvnObUYppDp2N1H/fNw3P0eQUv39H83ORe0N/nZdt4iMOmR5DIFSmVpatCG53E7/Nw86aRhhvLFtPG0HqnSzJYqdVU5oZZBIqQ34vf63G9zEQyqw2Bo3nNdVMEfJ5Vw0P7n57jhdvGXHVFuGv9YMUjqPz4dY6gwr5toxw+v1R5b+oRdVEzmWLDsDFHe2XlkJs8AiEEIyH3C885ZXA9aENQlUh/H7fvnuTfnpitOST75HySE/MpV1QLWdk1FeFMNMNStqDlJaqwb+sYUqOLeLkAABW4SURBVMKB51f3ChZdJC+hGAz6CPm9rjYEYCSM3Vw1VC5LkvmiI+QlQBuCmtx54zSLqTwPHVuouv7ewxcAuG23M0XmaqESxkfPJ7TgXBVu2jSM39tYniCado/gnEIIYfQSRKsbAjeUj4JRQupmQ5AulJDSGcqjoA1BTW7duY6hYB9fqiE58c3Dc+xeP8iGkYEuH1l77FpvaA49cz5h8Qjc8ePvBv19Xl6wcYhHTq5eObSYKrjOIwCzlyB+uSGIBHyO6HJthNFQoDJUyY04SXkUtCGoid/n4UevX89/PDVHakUrezSV58Bzi7zaZd4AwPRQP5F+H8+cX6p4BEMdGlPpVvZtHePJc0t1JQyklIZH4KJmMkW1prKlTME13gDA6EDfZUq6bkKpHOvOYhdw900zZAolvvn0pYqk9x25QFnimrJRK0IIdk8N8sysDg3VYt+2UUplycHna8+xXsq4t+JqZjjIYipPOr9s6Jay7pCXUIyGAixlizVzeE7HScqjoA1BXfZuHmFmOHhZeGj/4TkmBwNcNz3UoyNrj13rI5XQUCTgjnm73eTmTSN4PaJueEjJS4yF3WkIgEu8gnimwGDQGSelRlCemFt7CZIOGlMJ2hDUxeMR/MSN03zr2AILphuaK5Z44Mg8t+2edFX9uJVdU4Mkc0WeOhfXpaNVCAV8XD8zVFeAbtGF8hKKak1lbhGcU1RkJlLuzBMkKhLUznjPtSFYhbtunKFUlnz18XMAfPfkIql8ydGzB1ZDzSZ47HTMlSeybrBv2yiPn4mRyVef7xt1obyEQo2sPOtiQzBiegQXU73JE5ycT/LvTzauUrySZE7nCFzFzqkIu6YifOkxwxDsf3qOYJ+XF1011uMja52dk4YhKJSkzg/UYN/WUQolyaFT1fMEiy7uwZiMBPB6hMs9AlNmogcegZSSX//84/zyPx66JM/SDAldNeQ+7rpphsdOx3huIcX+w3O8fMe4qyd6hQI+No0aZa9acK46e7eM4hG1B9W42SPweT1MDfZXPIJcsUS2UHalIVjsgUfw4LEFDp2KUSpLHltFhqYWqiIt5NeGwDX8hKlI+kdfP8xsPMttLg4LKVRjmRacq85gfx/XTA/WnE+wmMrj93kY8LvzgmB6uL/SVOa2rmJY9sQWu+wRSCn58P6jTA4aOYqDz9WuLKtHwtQZckrfhjYEDTA9HGTf1lH+4+k5hIBX7XJf/8BKVGOZbiarzS1bxjh0KkaueHmeYDFldBU7fSpdLaxNZUsu6yoG6PN6GOz3db1q6FumN/Cu27azfV2YgzVCh6vhJME50IagYe66cQYwSgvHw4EeH0377DY9Aj2msjb7to2SK5Z54kz8snVGM5l737uZ4SCzsSylsnSlRwBGeKibCqTKG5ge6ucNezayd8sIjz4fpVyuL1dfjWTOOYJzoA1Bw7z2+vUMBfu488bpXh+KLVy/YQifR7B51F0SGd3kli3GoJpq/QSLLlQetTI9HKRYlswncq42BN1UIP3WsQUePRXjl191NX6fhz2bR1nKFjl2obFphlaWsgVHeQTOORKHMxTs45H33kbAtzZs54aRAb79nlexLuJ+76ZTjIT87JyM8Mizi7xzxbpousCMy3SmrKimsrOxjKsNwdkq85c7gZSSj9x7rOINAOzZbIynPfh8lJ2mh90oThpcD9ojaIr+Pq9rY8LVmBzsX1OvpxPs2zbKweejl0kZGDkCd504rVh7Cdw0lMbKyED3PIKHji9w8Pko73il4Q0AbBkbYCzkb0iyfCXJrDYEGo1r2Ld1jHS+xJNnl/MExVKZeMadyqMKa3dxPGOUMropWQzGyMrFVH7VkbLtYuQGjrF+qJ837N1QWS6EYM/mkbqaVLVw0phK0IZAo6nLLeZAe2s/gZI/dnOOIBzwMRTsMw1BgZDf6zrNqdEBP/lSmVSN7m+7+PbxixVvIOC7tFx4z+YRnr+YZj7RXD9DIuucoTSgDYFGU5eJSIBtE6FLEsZrZbLb9LAxoMZtXcWK5e7izoWHVKXQ+qF+fsriDSj2blnOEzRKuSy1R6DRuI19W8c48FyUklkmqATnxlzsEQDMDBvdxUtZd80iUChD0MkS0u+cuMiB56O849arLvMGAK6bGcLv9XCwiTxBKu8s5VHQhkCjWZUXbhslkStyeHYJWL4CdXOOAIzKIRUa0h7B5ShvYGqwn5/6oY1VHxPwebl+w1BTHsGy8qg2BBqNa1B5gu+a4SElOOfmHAEYoaGlbJGz0Yz2CKrwnRMX+f5zUd7xyuregGLv5hGePLtEttBYrkLpDOkcgUbjItYPBdk0OlCZT6CuQN2u3Dpt6SVwo0cw0kGPQErJR/YfM7yBvdW9AcWezSPkS2V+cPbyDvRqOE15FLQh0GgaYt/WUb733CLlsmQxZXSF1rtKdAOqlwDc10MAmNP1REc8godPXOR7zy3y9luvWlVp2NpY1ghJh42pBG0INJqGuGXrKLF0gaMXEiymcpXBKG5GdReDOw2BEKIjTWWqb2ByMMBP18gNWBkLB9g6HuJAg0qkanD9oPYINBp38cJtxiCi7z27yGK6wKjLS0cBJsIB+rxGZ7kbDQF0Rnju4ZOGN/COW69ueO7Ins0jPHoq2lBzW1KHhjQad7JhJMj0UD+PnFwk6nLBOYXHI1g/ZHgFbjYEdkpRN+sNKPZuHmExlefZhdSqj9WhIY3GpQghuGXrKI88e5HFVN71paOK6eF+wOWGwEaP4OGTF/nes4u8/RWr5wasqDzBgQbyBEvZIkI4ZzoZtGkIhBBvEEI8JYQoCyH2rlh3gxDiYXP9D4QQ/ebyPeb940KIPxOm6pkQYlQI8U0hxDHz70g7x6bR2M2+bWMsJPOcjWXWRGgIYGbYUFB1Y/ko2B8a+sj+Y6yLBHjjLZua2u6qiTBDwb6GJpYls0XCfh8eh0wng/Y9gieB1wEPWhcKIXzAZ4BfklJeC9wKqJlyfwG8Fdhu3l5jLn8PcK+Ucjtwr3lfo3EM+8x+AnB/M5lixuUewciAn3imQHGFOmwrPHziIo8821il0Eo8HkOArhEl0mSu4Kj8ALRpCKSUh6WUR6qs+mHgCSnl4+bjLkopS0KI9cCglPJhaWRVPgXcZW5zJ/BJ8/9PWpZrNI5g63iICXN+w1rIEQC8YOMwkX4fU0P9vT6UlhgLm70E6fZnF3/k3qNMRAK8qUlvQLFn8wgn5lOrhqqcpjMEncsR7ACkEOIeIcSjQojfMpfPAGcsjztjLgOYlFLOAph/3T8YWLOmUHkCcL/gnOK23ZM88fs/7LgTU6Ooz6HdhPHDJy7y3ZPN5wasqDzBo6vMMU44bBYBNGAIhBD7hRBPVrndWWczH/BS4GfMv3cLIW4DqgXFmhYTF0K8VQhxQAhxYH5+vtnNNZqWeaFpCNaKRwC4ejiREv67mGzPEChv4M37WvMGAF6wYRifR6yaME5ki4QdJC8BDYyqlFLe3sLzngEekFIuAAghvg7cjJE3sGq5bgDOmf/PCSHWSylnzRDShTrH9AngEwB79+7t7FQKjcbCT9w4w9xSjhs3Dvf6UDRYZCba8AgeOWl4A7/7Y9e07A0ABP1erp0eXLXDOJkrXtLM5wQ6FRq6B7hBCDFgJo5fATxthnwSQogXmtVCPwt82dzmK8BbzP/fYlmu0TiGoWAfv/EjOyvjCjW9RXkEi21UDn3uwGmGB/r4mTa8AcWezaM8fjpGvlg7eZ1w2OB6aL989G4hxBngRcDXhBD3AEgpo8D/Ab4PPAY8KqX8mrnZ24G/AY4DJ4BvmMv/BHi1EOIY8Grzvkaj0dRkeKA9Q1AuSx44Ms8rdky05Q0o9m4ZIVcs89S52gJ0TptXDA2Ehuohpfwi8MUa6z6DEQpaufwAcF2V5ReB29o5Ho1Gc2Xh93mI9PtaNgQ/OBvnYirPK3faU5tiFaC7adPlrVClsiSVL62t8lGNRqPpNaMhf8uG4P4j8wgBL98xYcuxTA72s2EkWDNPoKaTranQkEaj0fSakYHW9YbuO3KBF2wYtrUKbO/mEQ48X12ATs0iGHRY1ZA2BBqNxtWMhfwtlY8upvI8fibGrTvt8QYUe7aMMp/IcSaauWydE5VHQRsCjUbjckZaVCB98Og8UmJbfkCxZ5MSoLtcbiKZMzqgdWhIo9FobGTMFJ5rZBaAlfuPXGAs5Of6mSFbj2fnVIRIwFd1UM2S9gg0Go3GfkZCfvLFMul8Y8PjwajeeeCoUTZqtwqo1yO4cdNw1YRxspIj0IZAo9FobGO0haayJ87EiKYLvMLm/IBiz+YRjswlWMpeKoa3PJRGJ4s1Go3GNkZbaCq778g8HgEv394ZQ7B38yhSwqFTsUuW62SxRqPRdAClN7TYRML4gSMXuHHjcMfmSty4aRiP4LLwUCJbMKeTtd/FbCfaEGg0GldT0RtqsIR0IZnj8TNx26uFrIQDPnZNDXJwReVQwpxF4DTFV20INBqNq2lWgfTBo4Z0/a0dNARg6A4dOhW7ZHpaMlsk4rDSUdCGQKPRuJzBfh8+j2h4dvF9R+YZDwe4dnqwo8e1Z/MI6XyJZ84nKsuMWQTaEGg0Go2tCCGMprIGDEGpLHmwQ2WjK7EK0CmSuSIRh8lLgDYEGo1mDTDWoPDcY6ejxDMFXrmrM9VCVmaGg0wN9l8ysSzhwHnFoA2BRqNZA4wMNGYI7j8yj9cjeNnVnTcEQgj2bBnhUatHkC3o0JBGo9F0gtGQv6Hy0fuOXODmTcMMDXQnPLN38whnYxlm44YAXSJbdFxXMWhDoNFo1gCNzCS4kMjy5NmljlcLWVF5AqU7lNShIY1Go+kMIyE/8UzhklLNlTxwRJWNdj4spNi9fpBgn5eDz0cplSXpfMlx8hKgDYFGo1kDjIX8SAmxTKHmY+4/Os+6SIBr1ne2bNRKn9fDjRsNATqnykuANgQajWYNUGkqqxEeKpbKfOvoPLfunOh6V++ezSM8PbvEXCIL4LjB9aANgUajWQMomYlaTWWHTsdYyhY7KitRiz1bRiiVJd8+vgCgO4s1Go2mE4wM1PcI7nvmAj6P4CXbx7t5WADcbE4su9/MUejQkEaj0XSAsXB9BdL7j8yzZ/NIT4bGDwX72DEZ5rsnLwLozmKNRqPpBMNmX0A1BdK5pSxPz3a3bHQlezaPkisaFU26fFSj0Wg6QMDnJRzwVfUIVNloN2QlarHX7CcAnSzWaDSajlGrqey+IxeYGuxn52SkB0dlsMdiCLRHoNFoNB1ipIohKJTKPHRsgVfu6n7ZqJXNYwOMh/14BAw4bDoZaEOg0WjWCNUUSA8+HyWRK/KKHb3LD4ApQLd5xJHTyQCc56NoNBpNC4wM+HlmdumSZfcduUCfV/CSq8d6dFTL/OrtO7jjhmSvD6Mq2hBoNJo1wVj4cgXSB47Ms3fzqCNKNnevH2R3F+UtmkGHhjQazZpgZMBPtvB/27u3EKuqOI7j358zTumx0GPZxTRLDBICy4N0oywiqpcuJFQvBUE+JBT1kNVDvfQQdHuJwOj20JXuUHRFMnqIpohMnEjCzDQnmUyzYNL597DX1MHmNDNOc7Znr98HZGbWPnv4n+Xi/Gftvfb6D/H7YLGnz7Zdf9D3055SVwt1CicCM6uEei09S5DuE3zUpiL1VeBEYGaVUK8dBvyTCNb29TN35jQWzZlRZlgdwYnAzCqheUYwuG+ITzbt5PwSdhvtRE4EZlYJzTOC3s0D7B3cX8puo53Iq4bMrBLqaQfSgb2D9P20h56uKZy9sPxlo53AMwIzq4Qjp3XTNUUM7B1kbV8/y06qUzsEt3M4FDkRmFklSGLW9B7W//gr3/b/1tbaxJ3OicDMKqNem/p3JTAvGx07JwIzq4x6rYehgHn1aSw8ulZ2OB3DicDMKqOeahcvP2WOl42OgxOBmVXGcCLwthLj40RgZpWxYHaNIw/v5syTvWx0PLy2yswq44azF3D10hOY3uOPtvHwjMDMKqO7awoz04NlNnYTSgSSVkjaIGlIUqOpfaqkZyStl7RR0p1Nxy6R9I2kTZJWN7WfJOlTSd9KelGS/zfNzNpgojOCr4GrgHUHtK8ADouI04ClwEpJCyR1AY8ClwKLgWslLU7n3A88HBGLgF+AGycYm5mZjcGEEkFEbIyIb0Y6BNQkdQPTgEFgN7AM2BQR30XEIPACcLmKdV4XAi+n858BrphIbGZmNjaTdY/gZWAvsB3YAjwQEQPAXOCHptdtTW2zgV0Rse+AdjMzm2Sj3lqX9AFw7AiH7o6IN1qctgzYDxwPzAI+Tr9npCc84j/aW8V0E3ATwPz581sHb2Zmoxo1EUTERQfxe68D3omIP4F+SZ8ADYrZwLym150AbAN2AjMldadZwXB7q5jWAGsAGo1Gy4RhZmajm6xLQ1uAC1WoAWcCfcBnwKK0QqgHuAZ4MyICWAtcnc6/Hmg12zAzs//RRJePXilpK3AW8Jakd9OhR4EZFKuKPgOeioiv0l/7q4B3gY3ASxGxIZ1zB3CbpE0U9wyemEhsZmY2Nir+GO9cjUYjent7yw7DzOyQI+nziGiM9jo/WWxmlrmOnxFI+hn4/iBPP4riRnXOcu+D3N8/uA+gun1wYkSMuhVrxyeCiZDUO5ZpU5Xl3ge5v39wH4D7wJeGzMwy50RgZpa53BPBmrIDOATk3ge5v39wH0DmfZD1PQIzM/OMwMwse1kmglbFcXIiaXMqHPSlpCyeyJP0pKR+SV83tdUlvZ8KIr0vaVaZMU62Fn1wr6Qf01j4UtJlZcY42STNk7Q2Fc3aIOmW1J7VWGiWXSIYpThObi6IiCUZLZt7GrjkgLbVwIepINKH6ecqe5p/9wEURaGWpH9vtzmmdtsH3B4Rp1Lsg3Zz+gzIbSz8LbtEQIviOCXHZG0QEeuAgQOaL6cohAQZFERq0QdZiYjtEfFF+n4Pxb5nc8lsLDTLMRG0Ko6TmwDek/R5qu+Qq2MiYjsUHxDAnJLjKcsqSV+lS0fZXBKRtAA4HfiUjMdCjolgXEVwKuyciDiD4hLZzZLOKzsgK81jwEJgCUVVwQfLDac9JM0AXgFujYjdZcdTphwTwVZGLo6TlYjYlr72A69RXDLL0Q5JxwGkr/0lx9N2EbEjIvZHxBDwOBmMBUlTKZLAsxHxamrOdizkmAhGLI5TckxtJakm6Yjh74GLKWpH5OhNikJIkGlBpOEPv+RKKj4WJImi3snGiHio6VC2YyHLB8rS8rhHgC7gyYi4r+SQ2krSyRSzACjKlT6XQx9Ieh5YTrHT5A7gHuB14CVgPkVlvRURUdmbqS36YDnFZaEANgMrh6+VV5Gkc4GPgfXAUGq+i+I+QTZjoVmWicDMzP6R46UhMzNr4kRgZpY5JwIzs8w5EZiZZc6JwMwsc04EZmaZcyIwM8ucE4GZWeb+AnQyl4pvDRWoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 1.9806602001190186\n",
      "episode  26  start at  2019-05-21 21:04:03.754638\n",
      "[[0.00753522 0.99997161 0.96865415]]\n",
      "[[0.28799641]]\n",
      "(array([-0.08262201,  0.99658096,  1.80503178]), -2.5379459320117843, False, {})\n",
      "next_ [[-0.08262201  0.99658096  1.80503178]]\n",
      "[[0.17122099]]\n",
      "(array([-0.21130312,  0.97742058,  2.6038338 ]), -3.060035253152803, False, {})\n",
      "next_ [[-0.21130312  0.97742058  2.6038338 ]]\n",
      "[[0.32574579]]\n",
      "(array([-0.37522467,  0.9269339 ,  3.43462297]), -3.860020580901939, False, {})\n",
      "next_ [[-0.37522467  0.9269339   3.43462297]]\n",
      "[[0.64718884]]\n",
      "(array([-0.56533402,  0.82486207,  4.32398004]), -5.005066772917967, False, {})\n",
      "next_ [[-0.56533402  0.82486207  4.32398004]]\n",
      "[[-0.54015625]]\n",
      "(array([-0.74455443,  0.66756176,  4.78057973]), -6.586843684916378, False, {})\n",
      "next_ [[-0.74455443  0.66756176  4.78057973]]\n",
      "[[0.48754424]]\n",
      "(array([-0.89625064,  0.44354796,  5.42751432]), -8.097643345051585, False, {})\n",
      "next_ [[-0.89625064  0.44354796  5.42751432]]\n",
      "[[-0.64632046]]\n",
      "(array([-0.98362103,  0.18024893,  5.56627915]), -10.140796206105245, False, {})\n",
      "next_ [[-0.98362103  0.18024893  5.56627915]]\n",
      "[[0.45969093]]\n",
      "(array([-0.99387579, -0.110503  ,  5.83937313]), -11.862882268496104, False, {})\n",
      "next_ [[-0.99387579 -0.110503    5.83937313]]\n",
      "[[-0.82622874]]\n",
      "(array([-0.92636197, -0.37663443,  5.50862726]), -12.598692157625301, False, {})\n",
      "next_ [[-0.92636197 -0.37663443  5.50862726]]\n",
      "[[0.09390432]]\n",
      "(array([-0.79676314, -0.60429173,  5.25432273]), -10.626939083095525, False, {})\n",
      "next_ [[-0.79676314 -0.60429173  5.25432273]]\n",
      "[[0.9310829]]\n",
      "(array([-0.61933722, -0.78512509,  5.08042881]), -8.977891567554233, False, {})\n",
      "next_ [[-0.61933722 -0.78512509  5.08042881]]\n",
      "[[0.10701911]]\n",
      "(array([-0.42748933, -0.90402039,  4.52369073]), -7.592874930408653, False, {})\n",
      "next_ [[-0.42748933 -0.90402039  4.52369073]]\n",
      "[[-0.8017872]]\n",
      "(array([-0.25848807, -0.96601445,  3.60513927]), -6.099145912101089, False, {})\n",
      "next_ [[-0.25848807 -0.96601445  3.60513927]]\n",
      "[[0.33560058]]\n",
      "(array([-0.11215486, -0.99369074,  2.98130861]), -4.657304783033288, False, {})\n",
      "next_ [[-0.11215486 -0.99369074  2.98130861]]\n",
      "[[-0.62751889]]\n",
      "(array([-0.01000191, -0.99994998,  2.04778489]), -3.723515891770681, False, {})\n",
      "next_ [[-0.01000191 -0.99994998  2.04778489]]\n",
      "[[0.18418963]]\n",
      "(array([ 0.05761995, -0.99833859,  1.35307929]), -2.9184016008504114, False, {})\n",
      "next_ [[ 0.05761995 -0.99833859  1.35307929]]\n",
      "[[0.48598954]]\n",
      "(array([ 0.09501445, -0.99547589,  0.75012221]), -2.4736332038674695, False, {})\n",
      "next_ [[ 0.09501445 -0.99547589  0.75012221]]\n",
      "[[-0.82883251]]\n",
      "(array([ 0.08280635, -0.99656566, -0.24513446]), -2.2365246730201718, False, {})\n",
      "next_ [[ 0.08280635 -0.99656566 -0.24513446]]\n",
      "[[-0.25551525]]\n",
      "(array([ 0.02943636, -0.99956666, -1.06921328]), -2.2201019372869655, False, {})\n",
      "next_ [[ 0.02943636 -0.99956666 -1.06921328]]\n",
      "[[-0.7005688]]\n",
      "(array([-0.07195011, -0.99740823, -2.02905891]), -2.492062342383111, False, {})\n",
      "next_ [[-0.07195011 -0.99740823 -2.02905891]]\n",
      "[[0.04208825]]\n",
      "(array([-0.20869146, -0.97798153, -2.76448861]), -3.110535399501482, False, {})\n",
      "next_ [[-0.20869146 -0.97798153 -2.76448861]]\n",
      "[[-0.69269609]]\n",
      "(array([-0.38529358, -0.92279405, -3.70578359]), -3.9382379237206484, False, {})\n",
      "next_ [[-0.38529358 -0.92279405 -3.70578359]]\n",
      "[[0.50265056]]\n",
      "(array([-0.57112864, -0.82086057, -4.24708395]), -5.240717114635528, False, {})\n",
      "next_ [[-0.57112864 -0.82086057 -4.24708395]]\n",
      "[[0.5213654]]\n",
      "(array([-0.74677261, -0.66507944, -4.70631976]), -6.551490667741367, False, {})\n",
      "next_ [[-0.74677261 -0.66507944 -4.70631976]]\n",
      "[[0.69087601]]\n",
      "(array([-0.88805151, -0.45974397, -4.99786654]), -8.044213404484186, False, {})\n",
      "next_ [[-0.88805151 -0.45974397 -4.99786654]]\n",
      "[[0.51704478]]\n",
      "(array([-0.97626079, -0.21659841, -5.18756108]), -9.595223822851088, False, {})\n",
      "next_ [[-0.97626079 -0.21659841 -5.18756108]]\n",
      "[[0.19660696]]\n",
      "(array([-0.99893193,  0.04620612, -5.2910278 ]), -11.236705096766539, False, {})\n",
      "next_ [[-0.99893193  0.04620612 -5.2910278 ]]\n",
      "[[-0.64570725]]\n",
      "(array([-0.94963514,  0.31335778, -5.45008538]), -12.38248117791875, False, {})\n",
      "next_ [[-0.94963514  0.31335778 -5.45008538]]\n",
      "[[-0.29204109]]\n",
      "(array([-0.8343406 ,  0.55124927, -5.30267937]), -10.939255586399037, False, {})\n",
      "next_ [[-0.8343406   0.55124927 -5.30267937]]\n",
      "[[0.92339408]]\n",
      "(array([-0.68625252,  0.72736338, -4.6122242 ]), -9.357243638297595, False, {})\n",
      "next_ [[-0.68625252  0.72736338 -4.6122242 ]]\n",
      "[[0.09568591]]\n",
      "(array([-0.5264541 ,  0.85020355, -4.03799589]), -7.5427882457663875, False, {})\n",
      "next_ [[-0.5264541   0.85020355 -4.03799589]]\n",
      "[[-0.00901756]]\n",
      "(array([-0.3748844 ,  0.92707156, -3.40304849]), -6.147104998977478, False, {})\n",
      "next_ [[-0.3748844   0.92707156 -3.40304849]]\n",
      "[[-0.70676887]]\n",
      "(array([-0.23603479,  0.97174461, -2.91977548]), -4.982364478575926, False, {})\n",
      "next_ [[-0.23603479  0.97174461 -2.91977548]]\n",
      "[[0.38676506]]\n",
      "(array([-0.13413095,  0.99096362, -2.07493751]), -4.125876362004354, False, {})\n",
      "next_ [[-0.13413095  0.99096362 -2.07493751]]\n",
      "[[0.24913643]]\n",
      "(array([-0.07162635,  0.99743153, -1.25697387]), -3.3389446644344165, False, {})\n",
      "next_ [[-0.07162635  0.99743153 -1.25697387]]\n",
      "[[-0.07555392]]\n",
      "(array([-0.04509412,  0.99898274, -0.53156639]), -2.8557750729615416, False, {})\n",
      "next_ [[-0.04509412  0.99898274 -0.53156639]]\n",
      "[[-0.44095013]]\n",
      "(array([-0.04935864,  0.99878112,  0.08538563]), -2.640185414664406, False, {})\n",
      "next_ [[-0.04935864  0.99878112  0.08538563]]\n",
      "[[0.6640476]]\n",
      "(array([-0.10089104,  0.99489748,  1.03368575]), -2.627460030997247, False, {})\n",
      "next_ [[-0.10089104  0.99489748  1.03368575]]\n",
      "[[-0.44883475]]\n",
      "(array([-0.1822983 ,  0.98324327,  1.64520844]), -2.902770006086704, False, {})\n",
      "next_ [[-0.1822983   0.98324327  1.64520844]]\n",
      "[[0.34640935]]\n",
      "(array([-0.30282133,  0.95304734,  2.48656369]), -3.3480871322037986, False, {})\n",
      "next_ [[-0.30282133  0.95304734  2.48656369]]\n",
      "[[-0.57298362]]\n",
      "(array([-0.44316327,  0.89644092,  3.02945412]), -4.148179739516788, False, {})\n",
      "next_ [[-0.44316327  0.89644092  3.02945412]]\n",
      "[[-0.20201518]]\n",
      "(array([-0.59814415,  0.80138853,  3.64118025]), -5.038500222064936, False, {})\n",
      "next_ [[-0.59814415  0.80138853  3.64118025]]\n",
      "[[0.42953303]]\n",
      "(array([-0.7576712 ,  0.65263646,  4.37108156]), -6.2194112892136255, False, {})\n",
      "next_ [[-0.7576712   0.65263646  4.37108156]]\n",
      "[[0.46752924]]\n",
      "(array([-0.89560007,  0.4448601 ,  5.00081767]), -7.8190038906555195, False, {})\n",
      "next_ [[-0.89560007  0.4448601   5.00081767]]\n",
      "[[-0.43354842]]\n",
      "(array([-0.9799077 ,  0.1994515 ,  5.20439823]), -9.687049797764583, False, {})\n",
      "next_ [[-0.9799077   0.1994515   5.20439823]]\n",
      "[[-0.40696821]]\n",
      "(array([-0.99815245, -0.06075923,  5.23189639]), -11.357510954499668, False, {})\n",
      "next_ [[-0.99815245 -0.06075923  5.23189639]]\n",
      "[[0.34389329]]\n",
      "(array([-0.94756402, -0.31956599,  5.28949495]), -12.229050864289366, False, {})\n",
      "next_ [[-0.94756402 -0.31956599  5.28949495]]\n",
      "[[-0.35491034]]\n",
      "(array([-0.84058242, -0.54168367,  4.94334735]), -10.730044777969468, False, {})\n",
      "next_ [[-0.84058242 -0.54168367  4.94334735]]\n",
      "[[-0.56056434]]\n",
      "(array([-0.70321669, -0.71097559,  4.3689153 ]), -9.045476784421465, False, {})\n",
      "next_ [[-0.70321669 -0.71097559  4.3689153 ]]\n",
      "[[-0.07336938]]\n",
      "(array([-0.55571948, -0.83136987,  3.8136728 ]), -7.434592165589119, False, {})\n",
      "next_ [[-0.55571948 -0.83136987  3.8136728 ]]\n",
      "[[-0.82397634]]\n",
      "(array([-0.42782088, -0.90386354,  2.94295249]), -6.122831410489068, False, {})\n",
      "next_ [[-0.42782088 -0.90386354  2.94295249]]\n",
      "[[0.81928742]]\n",
      "(array([-0.31127886, -0.95031862,  2.51084106]), -4.9204549951009415, False, {})\n",
      "next_ [[-0.31127886 -0.95031862  2.51084106]]\n",
      "[[0.3376981]]\n",
      "(array([-0.21975944, -0.97555409,  1.89941153]), -4.1929210027072195, False, {})\n",
      "next_ [[-0.21975944 -0.97555409  1.89941153]]\n",
      "[[-0.78839898]]\n",
      "(array([-0.1741146 , -0.9847254 ,  0.93122627]), -3.5758321326746327, False, {})\n",
      "next_ [[-0.1741146  -0.9847254   0.93122627]]\n",
      "[[-0.15093549]]\n",
      "(array([-0.16685243, -0.98598188,  0.14740157]), -3.13463707954546, False, {})\n",
      "next_ [[-0.16685243 -0.98598188  0.14740157]]\n",
      "[[0.30941528]]\n",
      "(array([-0.19141097, -0.98150998, -0.49926025]), -3.0247042994961535, False, {})\n",
      "next_ [[-0.19141097 -0.98150998 -0.49926025]]\n",
      "[[-0.3348825]]\n",
      "(array([-0.25649329, -0.96654601, -1.33585749]), -3.134939482642301, False, {})\n",
      "next_ [[-0.25649329 -0.96654601 -1.33585749]]\n",
      "[[-0.78760135]]\n",
      "(array([-0.36556965, -0.93078399, -2.2970474 ]), -3.53052344195069, False, {})\n",
      "next_ [[-0.36556965 -0.93078399 -2.2970474 ]]\n",
      "[[0.77058959]]\n",
      "(array([-0.49030761, -0.87154945, -2.76395851]), -4.31320264938071, False, {})\n",
      "next_ [[-0.49030761 -0.87154945 -2.76395851]]\n",
      "[[-0.18750893]]\n",
      "(array([-0.6335526 , -0.77369962, -3.47387328]), -5.103971992801256, False, {})\n",
      "next_ [[-0.6335526  -0.77369962 -3.47387328]]\n",
      "[[-0.08006967]]\n",
      "(array([-0.77709993, -0.62937723, -4.0781689 ]), -6.300550204715466, False, {})\n",
      "next_ [[-0.77709993 -0.62937723 -4.0781689 ]]\n",
      "[[0.91772091]]\n",
      "(array([-0.89291966, -0.45021604, -4.27488555]), -7.722253916087876, False, {})\n",
      "next_ [[-0.89291966 -0.45021604 -4.27488555]]\n",
      "[[-0.20651565]]\n",
      "(array([-0.97291289, -0.23117202, -4.67450228]), -8.981042176504651, False, {})\n",
      "next_ [[-0.97291289 -0.23117202 -4.67450228]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51905626]]\n",
      "(array([-0.99985724,  0.01689694, -5.00359818]), -10.644444742284488, False, {})\n",
      "next_ [[-0.99985724  0.01689694 -5.00359818]]\n",
      "[[0.0869735]]\n",
      "(array([-0.96505598,  0.26204382, -4.96483342]), -12.26734799676378, False, {})\n",
      "next_ [[-0.96505598  0.26204382 -4.96483342]]\n",
      "[[0.63013488]]\n",
      "(array([-0.88039473,  0.47424162, -4.57926009]), -10.740528594846264, False, {})\n",
      "next_ [[-0.88039473  0.47424162 -4.57926009]]\n",
      "[[0.45593986]]\n",
      "(array([-0.76584478,  0.64302549, -4.08679692]), -9.106998357026695, False, {})\n",
      "next_ [[-0.76584478  0.64302549 -4.08679692]]\n",
      "[[0.40297604]]\n",
      "(array([-0.64281872,  0.76601834, -3.483635  ]), -7.639824277689657, False, {})\n",
      "next_ [[-0.64281872  0.76601834 -3.483635  ]]\n",
      "[[-0.10642046]]\n",
      "(array([-0.52364168,  0.85193861, -2.94104738]), -6.361835253707233, False, {})\n",
      "next_ [[-0.52364168  0.85193861 -2.94104738]]\n",
      "[[-0.48522839]]\n",
      "(array([-0.4157223 ,  0.9094916 , -2.44766194]), -5.368446401273061, False, {})\n",
      "next_ [[-0.4157223   0.9094916  -2.44766194]]\n",
      "[[0.1671481]]\n",
      "(array([-0.33628268,  0.94176109, -1.71539881]), -4.597349550729523, False, {})\n",
      "next_ [[-0.33628268  0.94176109 -1.71539881]]\n",
      "[[-0.00642705]]\n",
      "(array([-0.28826708,  0.95755005, -1.01100611]), -3.9567491734228937, False, {})\n",
      "next_ [[-0.28826708  0.95755005 -1.01100611]]\n",
      "[[-0.0409059]]\n",
      "(array([-0.27362594,  0.96183618, -0.30511534]), -3.5737824297100524, False, {})\n",
      "next_ [[-0.27362594  0.96183618 -0.30511534]]\n",
      "[[0.65281171]]\n",
      "(array([-0.30293046,  0.95301266,  0.61210531]), -3.4259598450207163, False, {})\n",
      "next_ [[-0.30293046  0.95301266  0.61210531]]\n",
      "[[-0.32667759]]\n",
      "(array([-0.36087801,  0.93261303,  1.22886153]), -3.566890940230682, False, {})\n",
      "next_ [[-0.36087801  0.93261303  1.22886153]]\n",
      "[[0.52246559]]\n",
      "(array([-0.45597037,  0.88999496,  2.08506098]), -3.9157232845622714, False, {})\n",
      "next_ [[-0.45597037  0.88999496  2.08506098]]\n",
      "[[-0.73307204]]\n",
      "(array([-0.56472005,  0.82528253,  2.53263558]), -4.615890518839064, False, {})\n",
      "next_ [[-0.56472005  0.82528253  2.53263558]]\n",
      "[[-0.01598445]]\n",
      "(array([-0.68705933,  0.72660132,  3.14680215]), -5.354190134415594, False, {})\n",
      "next_ [[-0.68705933  0.72660132  3.14680215]]\n",
      "[[-0.19476247]]\n",
      "(array([-0.80702716,  0.59051432,  3.6333244 ]), -6.411045061829439, False, {})\n",
      "next_ [[-0.80702716  0.59051432  3.6333244 ]]\n",
      "[[-0.470456]]\n",
      "(array([-0.90689434,  0.4213581 ,  3.93507334]), -7.6205711492535375, False, {})\n",
      "next_ [[-0.90689434  0.4213581   3.93507334]]\n",
      "[[0.56590903]]\n",
      "(array([-0.97721068,  0.21227175,  4.42086462]), -8.875717192915369, False, {})\n",
      "next_ [[-0.97721068  0.21227175  4.42086462]]\n",
      "[[0.29312411]]\n",
      "(array([-0.99980986, -0.01949995,  4.66800567]), -10.526137628479894, False, {})\n",
      "next_ [[-0.99980986 -0.01949995  4.66800567]]\n",
      "[[0.62325978]]\n",
      "(array([-0.96599833, -0.25854831,  4.84035864]), -11.928036656243929, False, {})\n",
      "next_ [[-0.96599833 -0.25854831  4.84035864]]\n",
      "[[0.01425756]]\n",
      "(array([-0.88041706, -0.47420018,  4.65072468]), -10.637731581889689, False, {})\n",
      "next_ [[-0.88041706 -0.47420018  4.65072468]]\n",
      "[[-0.10611595]]\n",
      "(array([-0.76017277, -0.64972098,  4.26323976]), -9.172422826417534, False, {})\n",
      "next_ [[-0.76017277 -0.64972098  4.26323976]]\n",
      "[[-0.36447886]]\n",
      "(array([-0.6289864 , -0.7774163 ,  3.66660536]), -7.744235888787826, False, {})\n",
      "next_ [[-0.6289864  -0.7774163   3.66660536]]\n",
      "[[-0.82052994]]\n",
      "(array([-0.51274541, -0.8585407 ,  2.83738416]), -6.414296379692397, False, {})\n",
      "next_ [[-0.51274541 -0.8585407   2.83738416]]\n",
      "[[-0.62180144]]\n",
      "(array([-0.42415864, -0.9055879 ,  2.0069382 ]), -5.25524416253776, False, {})\n",
      "next_ [[-0.42415864 -0.9055879   2.0069382 ]]\n",
      "[[-0.1351018]]\n",
      "(array([-0.36503628, -0.9309933 ,  1.28721673]), -4.438246777664443, False, {})\n",
      "next_ [[-0.36503628 -0.9309933   1.28721673]]\n",
      "[[-0.14792788]]\n",
      "(array([-0.33955345, -0.94058676,  0.5445934 ]), -3.9467363926304695, False, {})\n",
      "next_ [[-0.33955345 -0.94058676  0.5445934 ]]\n",
      "[[-0.74943769]]\n",
      "(array([-0.35762737, -0.93386437, -0.38567798]), -3.7077080009404946, False, {})\n",
      "next_ [[-0.35762737 -0.93386437 -0.38567798]]\n",
      "[[-0.33040318]]\n",
      "(array([-0.4123079 , -0.91104456, -1.18519721]), -3.765430125638751, False, {})\n",
      "next_ [[-0.4123079  -0.91104456 -1.18519721]]\n",
      "[[0.3283788]]\n",
      "(array([-0.4912151, -0.8710383, -1.769967 ]), -4.124047101258017, False, {})\n",
      "next_ [[-0.4912151 -0.8710383 -1.769967 ]]\n",
      "[[0.21678413]]\n",
      "(array([-0.59027117, -0.80720502, -2.35821048]), -4.657691643852081, False, {})\n",
      "next_ [[-0.59027117 -0.80720502 -2.35821048]]\n",
      "[[-0.00038619]]\n",
      "(array([-0.70298165, -0.71120798, -2.96373011]), -5.405761127082346, False, {})\n",
      "next_ [[-0.70298165 -0.71120798 -2.96373011]]\n",
      "[[0.33405113]]\n",
      "(array([-0.81308223, -0.58214886, -3.39692076]), -6.40309067008626, False, {})\n",
      "next_ [[-0.81308223 -0.58214886 -3.39692076]]\n",
      "[[0.14956555]]\n",
      "(array([-0.90815702, -0.4186297 , -3.78866274]), -7.505523545800285, False, {})\n",
      "next_ [[-0.90815702 -0.4186297  -3.78866274]]\n",
      "[[-0.73867768]]\n",
      "(array([-0.97682167, -0.2140547 , -4.32423832]), -8.779818752980717, False, {})\n",
      "next_ [[-0.97682167 -0.2140547  -4.32423832]]\n",
      "[[-0.43699878]]\n",
      "(array([-0.99988645,  0.01506938, -4.61587898]), -10.431374955945776, False, {})\n",
      "next_ [[-0.99988645  0.01506938 -4.61587898]]\n",
      "[[0.31178841]]\n",
      "(array([-0.97118994,  0.23830672, -4.51104042]), -11.906166939919157, False, {})\n",
      "next_ [[-0.97118994  0.23830672 -4.51104042]]\n",
      "[[-0.31021783]]\n",
      "(array([-0.8952115 ,  0.44564153, -4.42537573]), -10.450964410730972, False, {})\n",
      "next_ [[-0.8952115   0.44564153 -4.42537573]]\n",
      "[[-0.01694789]]\n",
      "(array([-0.78586528,  0.61839773, -4.09622894]), -9.139198434666307, False, {})\n",
      "next_ [[-0.78586528  0.61839773 -4.09622894]]\n",
      "[[0.65915167]]\n",
      "(array([-0.66862629,  0.74359861, -3.43468514]), -7.804729816473229, False, {})\n",
      "next_ [[-0.66862629  0.74359861 -3.43468514]]\n",
      "[[0.45310411]]\n",
      "(array([-0.56076307,  0.82797632, -2.74105496]), -6.485055862511284, False, {})\n",
      "next_ [[-0.56076307  0.82797632 -2.74105496]]\n",
      "[[0.19191954]]\n",
      "(array([-0.47255026,  0.88130372, -2.06249686]), -5.44348969129069, False, {})\n",
      "next_ [[-0.47255026  0.88130372 -2.06249686]]\n",
      "[[-0.15446903]]\n",
      "(array([-0.40756804,  0.91317484, -1.44785977]), -4.681365481271017, False, {})\n",
      "next_ [[-0.40756804  0.91317484 -1.44785977]]\n",
      "[[0.7718972]]\n",
      "(array([-0.38316355,  0.92368052, -0.53140948]), -4.174444174932785, False, {})\n",
      "next_ [[-0.38316355  0.92368052 -0.53140948]]\n",
      "[[-0.23212875]]\n",
      "(array([-0.38739515,  0.92191377,  0.09171228]), -3.8858106031489004, False, {})\n",
      "next_ [[-0.38739515  0.92191377  0.09171228]]\n",
      "[[-0.48800626]]\n",
      "(array([-0.4165451 ,  0.90911505,  0.63674573]), -3.877182636570264, False, {})\n",
      "next_ [[-0.4165451   0.90911505  0.63674573]]\n",
      "[[-0.67320776]]\n",
      "(array([-0.46662649,  0.88445448,  1.11661969]), -4.044109692666407, False, {})\n",
      "next_ [[-0.46662649  0.88445448  1.11661969]]\n",
      "[[-0.02447647]]\n",
      "(array([-0.5430823 ,  0.83967947,  1.7726176 ]), -4.352928642831686, False, {})\n",
      "next_ [[-0.5430823   0.83967947  1.7726176 ]]\n",
      "[[0.17787898]]\n",
      "(array([-0.64183639,  0.7668416 ,  2.4557409 ]), -4.914939472357932, False, {})\n",
      "next_ [[-0.64183639  0.7668416   2.4557409 ]]\n",
      "[[-0.08336703]]\n",
      "(array([-0.74941873,  0.66209634,  3.00586199]), -5.745498227758023, False, {})\n",
      "next_ [[-0.74941873  0.66209634  3.00586199]]\n",
      "[[0.27996749]]\n",
      "(array([-0.85549444,  0.517812  ,  3.58642449]), -6.750461666688943, False, {})\n",
      "next_ [[-0.85549444  0.517812    3.58642449]]\n",
      "[[-0.17758855]]\n",
      "(array([-0.93998294,  0.34122145,  3.92150693]), -8.032344112050987, False, {})\n",
      "next_ [[-0.93998294  0.34122145  3.92150693]]\n",
      "[[-0.90428811]]\n",
      "(array([-0.98833215,  0.15231403,  3.90613659]), -9.344045538722654, False, {})\n",
      "next_ [[-0.98833215  0.15231403  3.90613659]]\n",
      "[[-0.99829525]]\n",
      "(array([-0.99945109, -0.03312891,  3.72088354]), -10.462005426287737, False, {})\n",
      "next_ [[-0.99945109 -0.03312891  3.72088354]]\n",
      "[[-0.99998933]]\n",
      "(array([-0.97947887, -0.2015469 ,  3.39604006]), -11.051006510018036, False, {})\n",
      "next_ [[-0.97947887 -0.2015469   3.39604006]]\n",
      "[[-0.99999571]]\n",
      "(array([-0.93931062, -0.34306786,  2.94488117]), -9.79300597754253, False, {})\n",
      "next_ [[-0.93931062 -0.34306786  2.94488117]]\n",
      "[[-0.92054194]]\n",
      "(array([-0.8912275 , -0.45355654,  2.41141769]), -8.662600940193721, False, {})\n",
      "next_ [[-0.8912275  -0.45355654  2.41141769]]\n",
      "[[0.1944326]]\n",
      "(array([-0.83797696, -0.54570561,  2.12958007]), -7.715034985909204, False, {})\n",
      "next_ [[-0.83797696 -0.54570561  2.12958007]]\n",
      "[[-0.01333688]]\n",
      "(array([-0.78812107, -0.61552025,  1.7162998 ]), -7.029462936756063, False, {})\n",
      "next_ [[-0.78812107 -0.61552025  1.7162998 ]]\n",
      "[[0.63278532]]\n",
      "(array([-0.74164922, -0.67078792,  1.44449521]), -6.439364127693219, False, {})\n",
      "next_ [[-0.74164922 -0.67078792  1.44449521]]\n",
      "[[0.08006646]]\n",
      "(array([-0.70841815, -0.70579297,  0.9654242 ]), -5.999067768838079, False, {})\n",
      "next_ [[-0.70841815 -0.70579297  0.9654242 ]]\n",
      "[[0.8311882]]\n",
      "(array([-0.6838181 , -0.72965253,  0.68543593]), -5.656371332006322, False, {})\n",
      "next_ [[-0.6838181  -0.72965253  0.68543593]]\n",
      "[[0.32874861]]\n",
      "(array([-0.6751305 , -0.73769832,  0.23682112]), -5.447363274541001, False, {})\n",
      "next_ [[-0.6751305  -0.73769832  0.23682112]]\n",
      "[[0.80164701]]\n",
      "(array([-0.67792735, -0.73512891, -0.07595851]), -5.353235922099052, False, {})\n",
      "next_ [[-0.67792735 -0.73512891 -0.07595851]]\n",
      "[[0.42406338]]\n",
      "(array([-0.69609491, -0.71794977, -0.50008618]), -5.363928795152127, False, {})\n",
      "next_ [[-0.69609491 -0.71794977 -0.50008618]]\n",
      "[[0.09358648]]\n",
      "(array([-0.73146466, -0.68187935, -1.01047256]), -5.50410812230804, False, {})\n",
      "next_ [[-0.73146466 -0.68187935 -1.01047256]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20390311]]\n",
      "(array([-0.78309071, -0.6219075 , -1.58305301]), -5.820414262226659, False, {})\n",
      "next_ [[-0.78309071 -0.6219075  -1.58305301]]\n",
      "[[0.22728691]]\n",
      "(array([-0.84075975, -0.54140839, -1.98129757]), -6.35376967155592, False, {})\n",
      "next_ [[-0.84075975 -0.54140839 -1.98129757]]\n",
      "[[0.21630497]]\n",
      "(array([-0.8978263 , -0.44034978, -2.32246236]), -6.994975363583682, False, {})\n",
      "next_ [[-0.8978263  -0.44034978 -2.32246236]]\n",
      "[[-0.02581373]]\n",
      "(array([-0.94829863, -0.31737945, -2.66046882]), -7.751856958459291, False, {})\n",
      "next_ [[-0.94829863 -0.31737945 -2.66046882]]\n",
      "[[0.94236654]]\n",
      "(array([-0.98159112, -0.19099441, -2.61579345]), -8.656024723080014, False, {})\n",
      "next_ [[-0.98159112 -0.19099441 -2.61579345]]\n",
      "[[-0.34427124]]\n",
      "(array([-0.99879684, -0.0490394 , -2.86232063]), -9.38377546546654, False, {})\n",
      "next_ [[-0.99879684 -0.0490394  -2.86232063]]\n",
      "[[-0.62057358]]\n",
      "(array([-0.99447111,  0.10501057, -3.08527226]), -10.384592290748389, False, {})\n",
      "next_ [[-0.99447111  0.10501057 -3.08527226]]\n",
      "[[0.08371533]]\n",
      "(array([-0.96784604,  0.25154332, -2.98139973]), -10.171571340303935, False, {})\n",
      "next_ [[-0.96784604  0.25154332 -2.98139973]]\n",
      "[[0.02045872]]\n",
      "(array([-0.92353257,  0.38352   , -2.78660462]), -9.225482115225503, False, {})\n",
      "next_ [[-0.92353257  0.38352    -2.78660462]]\n",
      "[[-0.48524886]]\n",
      "(array([-0.86490678,  0.50193253, -2.64453928]), -8.328895912408983, False, {})\n",
      "next_ [[-0.86490678  0.50193253 -2.64453928]]\n",
      "[[0.04087763]]\n",
      "(array([-0.80291731,  0.59609042, -2.25582659]), -7.541570773636809, False, {})\n",
      "next_ [[-0.80291731  0.59609042 -2.25582659]]\n",
      "[[-0.76509345]]\n",
      "(array([-0.7381061 ,  0.67468466, -2.0382868 ]), -6.776073699006022, False, {})\n",
      "next_ [[-0.7381061   0.67468466 -2.0382868 ]]\n",
      "[[0.74508393]]\n",
      "(array([-0.69240825,  0.72150594, -1.30874813]), -6.182748317320759, False, {})\n",
      "next_ [[-0.69240825  0.72150594 -1.30874813]]\n",
      "[[-0.81927967]]\n",
      "(array([-0.65497641,  0.75564932, -1.01340258]), -5.629077846283075, False, {})\n",
      "next_ [[-0.65497641  0.75564932 -1.01340258]]\n",
      "[[0.04707295]]\n",
      "(array([-0.63848195,  0.7696368 , -0.4325437 ]), -5.323693489506718, False, {})\n",
      "next_ [[-0.63848195  0.7696368  -0.4325437 ]]\n",
      "[[-0.5974654]]\n",
      "(array([-0.63715123,  0.77073881, -0.03455572]), -5.142757171969348, False, {})\n",
      "next_ [[-0.63715123  0.77073881 -0.03455572]]\n",
      "[[-0.59322304]]\n",
      "(array([-0.6511305 ,  0.75896579,  0.36553147]), -5.116328888489766, False, {})\n",
      "next_ [[-0.6511305   0.75896579  0.36553147]]\n",
      "[[0.15312959]]\n",
      "(array([-0.68754864,  0.72613833,  0.9806947 ]), -5.211259311630231, False, {})\n",
      "next_ [[-0.68754864  0.72613833  0.9806947 ]]\n",
      "[[0.05975805]]\n",
      "(array([-0.74147706,  0.67097822,  1.54322586]), -5.51998466601335, False, {})\n",
      "next_ [[-0.74147706  0.67097822  1.54322586]]\n",
      "[[-0.20846222]]\n",
      "(array([-0.80428132,  0.59424874,  1.98392086]), -6.0274789669450755, False, {})\n",
      "next_ [[-0.80428132  0.59424874  1.98392086]]\n",
      "[[-0.09346694]]\n",
      "(array([-0.86967495,  0.49362483,  2.40156733]), -6.669963857846291, False, {})\n",
      "next_ [[-0.86967495  0.49362483  2.40156733]]\n",
      "[[0.69633818]]\n",
      "(array([-0.93332957,  0.35902078,  2.98068741]), -7.471101034554814, False, {})\n",
      "next_ [[-0.93332957  0.35902078  2.98068741]]\n",
      "[[0.86323047]]\n",
      "(array([-0.98166796,  0.19059911,  3.50892213]), -8.588582296264656, False, {})\n",
      "next_ [[-0.98166796  0.19059911  3.50892213]]\n",
      "[[0.04292697]]\n",
      "(array([-0.99996358,  0.00853482,  3.66474955]), -9.932700327980736, False, {})\n",
      "next_ [[-0.99996358  0.00853482  3.66474955]]\n",
      "[[0.55605257]]\n",
      "(array([-0.98323598, -0.18233761,  3.83796644]), -11.16032642725775, False, {})\n",
      "next_ [[-0.98323598 -0.18233761  3.83796644]]\n",
      "[[-0.96958989]]\n",
      "(array([-0.93803513, -0.34654018,  3.41033626]), -10.227879397494767, False, {})\n",
      "next_ [[-0.93803513 -0.34654018  3.41033626]]\n",
      "[[-0.80205053]]\n",
      "(array([-0.87788394, -0.47887345,  2.90981597]), -8.936953157444941, False, {})\n",
      "next_ [[-0.87788394 -0.47887345  2.90981597]]\n",
      "[[-0.74333352]]\n",
      "(array([-0.81633816, -0.57757424,  2.32766082]), -7.830248304788542, False, {})\n",
      "next_ [[-0.81633816 -0.57757424  2.32766082]]\n",
      "[[-0.58432835]]\n",
      "(array([-0.76373744, -0.64552702,  1.71918164]), -6.923026909583727, False, {})\n",
      "next_ [[-0.76373744 -0.64552702  1.71918164]]\n",
      "[[0.78858435]]\n",
      "(array([-0.71421549, -0.69992588,  1.47161168]), -6.251058099525263, False, {})\n",
      "next_ [[-0.71421549 -0.69992588  1.47161168]]\n",
      "[[-0.8781907]]\n",
      "(array([-0.68989363, -0.72391075,  0.68321006]), -5.819019640057289, False, {})\n",
      "next_ [[-0.68989363 -0.72391075  0.68321006]]\n",
      "[[-0.55213284]]\n",
      "(array([-0.6908111 , -0.72303528, -0.02536286]), -5.486766688378566, False, {})\n",
      "next_ [[-0.6908111  -0.72303528 -0.02536286]]\n",
      "[[-0.4364967]]\n",
      "(array([-0.71563979, -0.69846953, -0.69858833]), -5.445612709473599, False, {})\n",
      "next_ [[-0.71563979 -0.69846953 -0.69858833]]\n",
      "[[0.16606297]]\n",
      "(array([-0.75533867, -0.65533465, -1.17262159]), -5.657928262805574, False, {})\n",
      "next_ [[-0.75533867 -0.65533465 -1.17262159]]\n",
      "[[-0.11776379]]\n",
      "(array([-0.8082319 , -0.58886433, -1.69945171]), -6.027728798004035, False, {})\n",
      "next_ [[-0.8082319  -0.58886433 -1.69945171]]\n",
      "[[-0.49173316]]\n",
      "(array([-0.87018336, -0.49272804, -2.28861991]), -6.599621680428641, False, {})\n",
      "next_ [[-0.87018336 -0.49272804 -2.28861991]]\n",
      "[[0.56902993]]\n",
      "(array([-0.92458589, -0.38097366, -2.48745696]), -7.422896117021906, False, {})\n",
      "next_ [[-0.92458589 -0.38097366 -2.48745696]]\n",
      "[[0.01146377]]\n",
      "(array([-0.96832542, -0.24969159, -2.76974808]), -8.185334569765065, False, {})\n",
      "next_ [[-0.96832542 -0.24969159 -2.76974808]]\n",
      "[[0.64773643]]\n",
      "(array([-0.99348319, -0.11397871, -2.76269584]), -9.116483938156849, False, {})\n",
      "next_ [[-0.99348319 -0.11397871 -2.76269584]]\n",
      "[[0.17288814]]\n",
      "(array([-0.99967263,  0.02558593, -2.79631344]), -9.92831148298702, False, {})\n",
      "next_ [[-0.99967263  0.02558593 -2.79631344]]\n",
      "[[0.76319909]]\n",
      "(array([-0.98831878,  0.15240074, -2.54816426]), -10.493747292539112, False, {})\n",
      "next_ [[-0.98831878  0.15240074 -2.54816426]]\n",
      "[[0.84876692]]\n",
      "(array([-0.9658846 ,  0.25897284, -2.17923363]), -9.583900116262733, False, {})\n",
      "next_ [[-0.9658846   0.25897284 -2.17923363]]\n",
      "[[-0.3824999]]\n",
      "(array([-0.93342726,  0.35876671, -2.09975397]), -8.767783348320362, False, {})\n",
      "next_ [[-0.93342726  0.35876671 -2.09975397]]\n",
      "[[-0.21007551]]\n",
      "(array([-0.89532705,  0.44540933, -1.89370159]), -8.139735517557318, False, {})\n",
      "next_ [[-0.89532705  0.44540933 -1.89370159]]\n",
      "[[-0.04650093]]\n",
      "(array([-0.85754867,  0.51440283, -1.57359487]), -7.540811582326253, False, {})\n",
      "next_ [[-0.85754867  0.51440283 -1.57359487]]\n",
      "[[-0.37779695]]\n",
      "(array([-0.82229289,  0.56906449, -1.30113183]), -7.0148565381953, False, {})\n",
      "next_ [[-0.82229289  0.56906449 -1.30113183]]\n",
      "[[-0.33291209]]\n",
      "(array([-0.79360919,  0.60842786, -0.97420709]), -6.60217460114758, False, {})\n",
      "next_ [[-0.79360919  0.60842786 -0.97420709]]\n",
      "[[0.40454102]]\n",
      "(array([-0.7813912 ,  0.6240415 , -0.39652389]), -6.28329130145587, False, {})\n",
      "next_ [[-0.7813912   0.6240415  -0.39652389]]\n",
      "[[0.83805215]]\n",
      "(array([-0.79136477,  0.61134425,  0.32292288]), -6.108018369900631, False, {})\n",
      "next_ [[-0.79136477  0.61134425  0.32292288]]\n",
      "[[-0.58990073]]\n",
      "(array([-0.80947724,  0.58715126,  0.60446085]), -6.181253777358882, False, {})\n",
      "next_ [[-0.80947724  0.58715126  0.60446085]]\n",
      "[[0.12258526]]\n",
      "(array([-0.84003147,  0.54253767,  1.08159987]), -6.357082834021721, False, {})\n",
      "next_ [[-0.84003147  0.54253767  1.08159987]]\n",
      "[[0.42693844]]\n",
      "(array([-0.88109402,  0.47294115,  1.61658466]), -6.713045447345154, False, {})\n",
      "next_ [[-0.88109402  0.47294115  1.61658466]]\n",
      "[[0.91151726]]\n",
      "(array([-0.92852043,  0.3712813 ,  2.2447457 ]), -7.2816831070269155, False, {})\n",
      "next_ [[-0.92852043  0.3712813   2.2447457 ]]\n",
      "[[-0.74194765]]\n",
      "(array([-0.96499882,  0.26225423,  2.30062238]), -8.130338216284992, False, {})\n",
      "next_ [[-0.96499882  0.26225423  2.30062238]]\n",
      "[[0.27081865]]\n",
      "(array([-0.99070792,  0.13600669,  2.57855865]), -8.802308597240522, False, {})\n",
      "next_ [[-0.99070792  0.13600669  2.57855865]]\n",
      "[[-0.90466398]]\n",
      "(array([-0.99987246,  0.01597062,  2.40916448]), -9.699175557125654, False, {})\n",
      "next_ [[-0.99987246  0.01597062  2.40916448]]\n",
      "[[-0.74432319]]\n",
      "(array([-0.99559267, -0.09378295,  2.19784549]), -10.352132242041826, False, {})\n",
      "next_ [[-0.99559267 -0.09378295  2.19784549]]\n",
      "[[0.76024729]]\n",
      "(array([-0.9776751 , -0.21012234,  2.35558246]), -9.773667065102291, False, {})\n",
      "next_ [[-0.9776751  -0.21012234  2.35558246]]\n",
      "[[-0.27779719]]\n",
      "(array([-0.95003988, -0.31212853,  2.11465155]), -9.139455967134742, False, {})\n",
      "next_ [[-0.95003988 -0.31212853  2.11465155]]\n",
      "[[-0.34268644]]\n",
      "(array([-0.91858144, -0.39523175,  1.77774922]), -8.423524456389675, False, {})\n",
      "next_ [[-0.91858144 -0.39523175  1.77774922]]\n",
      "[[0.11275124]]\n",
      "(array([-0.88603358, -0.46362106,  1.51515077]), -7.797805844790088, False, {})\n",
      "next_ [[-0.88603358 -0.46362106  1.51515077]]\n",
      "[[-0.90166318]]\n",
      "(array([-0.86435777, -0.50287737,  0.89693602]), -7.305840115451334, False, {})\n",
      "next_ [[-0.86435777 -0.50287737  0.89693602]]\n",
      "[[-0.81685275]]\n",
      "(array([-0.85736887, -0.51470247,  0.27472217]), -6.919608116188844, False, {})\n",
      "next_ [[-0.85736887 -0.51470247  0.27472217]]\n",
      "[[0.67961329]]\n",
      "(array([-0.85497715, -0.51866567,  0.09257931]), -6.774242372504567, False, {})\n",
      "next_ [[-0.85497715 -0.51866567  0.09257931]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.92099822]]\n",
      "(array([-0.86947709, -0.49397327, -0.5727194 ]), -6.745039869692583, False, {})\n",
      "next_ [[-0.86947709 -0.49397327 -0.5727194 ]]\n",
      "[[0.62204027]]\n",
      "(array([-0.88753726, -0.46073594, -0.75658728]), -6.924653649891225, False, {})\n",
      "next_ [[-0.88753726 -0.46073594 -0.75658728]]\n",
      "[[0.14450377]]\n",
      "(array([-0.91067355, -0.41312671, -1.0587881 ]), -7.147661729166909, False, {})\n",
      "next_ [[-0.91067355 -0.41312671 -1.0587881 ]]\n",
      "[[-0.32071948]]\n",
      "(array([-0.93846338, -0.34537877, -1.46484898]), -7.487583774837324, False, {})\n",
      "next_ [[-0.93846338 -0.34537877 -1.46484898]]\n",
      "[[0.86027575]]\n",
      "(array([-0.96123422, -0.27573316, -1.46580033]), -7.99578229997495, False, {})\n",
      "next_ [[-0.96123422 -0.27573316 -1.46580033]]\n",
      "[[-0.17043591]]\n",
      "(array([-0.98140143, -0.19196677, -1.72373097]), -8.40739285648329, False, {})\n",
      "next_ [[-0.98140143 -0.19196677 -1.72373097]]\n",
      "[[0.31067109]]\n",
      "(array([-0.99455104, -0.10425079, -1.77450471]), -8.990731860456448, True, {})\n",
      "next_ [[-0.99455104 -0.10425079 -1.77450471]]\n",
      "26 1.9287993907928467\n",
      "episode  27  start at  2019-05-21 21:04:05.683488\n",
      "[[-0.12245681 -0.99247384  0.76136201]]\n",
      "[[-0.94219768]]\n",
      "(array([-0.13562828, -0.99075979, -0.26565268]), -2.9296679399266976, False, {})\n",
      "next_ [[-0.13562828 -0.99075979 -0.26565268]]\n",
      "[[0.28748691]]\n",
      "(array([-0.18116547, -0.98345263, -0.92247645]), -2.920703848737328, False, {})\n",
      "next_ [[-0.18116547 -0.98345263 -0.92247645]]\n",
      "[[0.55808991]]\n",
      "(array([-0.25399003, -0.96720684, -1.49263895]), -3.1592379936524786, False, {})\n",
      "next_ [[-0.25399003 -0.96720684 -1.49263895]]\n",
      "[[-0.10862263]]\n",
      "(array([-0.36099525, -0.93256765, -2.25063086]), -3.562964871872774, False, {})\n",
      "next_ [[-0.36099525 -0.93256765 -2.25063086]]\n",
      "[[0.01381865]]\n",
      "(array([-0.49395316, -0.86948852, -2.94591101]), -4.270643837368946, False, {})\n",
      "next_ [[-0.49395316 -0.86948852 -2.94591101]]\n",
      "[[0.86552042]]\n",
      "(array([-0.63154867, -0.77533624, -3.33837127]), -5.228186185122332, False, {})\n",
      "next_ [[-0.63154867 -0.77533624 -3.33837127]]\n",
      "[[-0.11566032]]\n",
      "(array([-0.77155226, -0.63616594, -3.95457154]), -6.196598660907639, False, {})\n",
      "next_ [[-0.77155226 -0.63616594 -3.95457154]]\n",
      "[[-0.30531877]]\n",
      "(array([-0.89455839, -0.44695111, -4.52329163]), -7.576902944617637, False, {})\n",
      "next_ [[-0.89455839 -0.44695111 -4.52329163]]\n",
      "[[-0.83084452]]\n",
      "(array([-0.97845285, -0.2064704 , -5.10775832]), -9.221739342984213, False, {})\n",
      "next_ [[-0.97845285 -0.2064704  -5.10775832]]\n",
      "[[-0.07006032]]\n",
      "(array([-0.99842034,  0.05618561, -5.28362921]), -11.21510303439512, False, {})\n",
      "next_ [[-0.99842034  0.05618561 -5.28362921]]\n",
      "[[-0.8569833]]\n",
      "(array([-0.94567087,  0.32512553, -5.498585  ]), -12.314165390614534, False, {})\n",
      "next_ [[-0.94567087  0.32512553 -5.498585  ]]\n",
      "[[0.36316645]]\n",
      "(array([-0.83181092,  0.5550591 , -5.14579091]), -10.922590281558673, False, {})\n",
      "next_ [[-0.83181092  0.5550591  -5.14579091]]\n",
      "[[0.39208448]]\n",
      "(array([-0.68293187,  0.73048207, -4.61187125]), -9.16715039585522, False, {})\n",
      "next_ [[-0.68293187  0.73048207 -4.61187125]]\n",
      "[[-0.93252778]]\n",
      "(array([-0.50947999,  0.86048251, -4.34376803]), -7.524722631698577, False, {})\n",
      "next_ [[-0.50947999  0.86048251 -4.34376803]]\n",
      "[[-0.63201928]]\n",
      "(array([-0.33365655,  0.9426947 , -3.88801193]), -6.321040826929303, False, {})\n",
      "next_ [[-0.33365655  0.9426947  -3.88801193]]\n",
      "[[-0.03851248]]\n",
      "(array([-0.17957314,  0.98374462, -3.19254465]), -5.1634992034280645, False, {})\n",
      "next_ [[-0.17957314  0.98374462 -3.19254465]]\n",
      "[[0.55282265]]\n",
      "(array([-0.06605991,  0.99781566, -2.28888938]), -4.087679382667591, False, {})\n",
      "next_ [[-0.06605991  0.99781566 -2.28888938]]\n",
      "[[0.41109478]]\n",
      "(array([ 0.00475189,  0.99998871, -1.4171992 ]), -3.2040334128368513, False, {})\n",
      "next_ [[ 0.00475189  0.99998871 -1.4171992 ]]\n",
      "[[-0.01690867]]\n",
      "(array([ 0.03835651,  0.99926412, -0.67228027]), -2.6533416332660598, False, {})\n",
      "next_ [[ 0.03835651  0.99926412 -0.67228027]]\n",
      "[[0.50961071]]\n",
      "(array([0.02686014, 0.9996392 , 0.23005103]), -2.3945778445990675, False, {})\n",
      "next_ [[0.02686014 0.9996392  0.23005103]]\n",
      "[[0.8716681]]\n",
      "(array([-0.03519341,  0.99938052,  1.24128086]), -2.3920605518869715, False, {})\n",
      "next_ [[-0.03519341  0.99938052  1.24128086]]\n",
      "[[-0.6687355]]\n",
      "(array([-0.12438744,  0.99223372,  1.7901956 ]), -2.735093017474839, False, {})\n",
      "next_ [[-0.12438744  0.99223372  1.7901956 ]]\n",
      "[[-0.67177474]]\n",
      "(array([-0.23901603,  0.97101562,  2.33283847]), -3.1970284018820414, False, {})\n",
      "next_ [[-0.23901603  0.97101562  2.33283847]]\n",
      "[[-0.40239802]]\n",
      "(array([-0.37868162,  0.925527  ,  2.94038078]), -3.828744159832642, False, {})\n",
      "next_ [[-0.37868162  0.925527    2.94038078]]\n",
      "[[-0.46128619]]\n",
      "(array([-0.53387645,  0.8455625 ,  3.49614017]), -4.703773303767864, False, {})\n",
      "next_ [[-0.53387645  0.8455625   3.49614017]]\n",
      "[[0.25410277]]\n",
      "(array([-0.69864764,  0.71546591,  4.20654288]), -5.77640613180948, False, {})\n",
      "next_ [[-0.69864764  0.71546591  4.20654288]]\n",
      "[[0.49523264]]\n",
      "(array([-0.85110746,  0.52499152,  4.8917121 ]), -7.266232703889377, False, {})\n",
      "next_ [[-0.85110746  0.52499152  4.8917121 ]]\n",
      "[[-0.33370876]]\n",
      "(array([-0.95725511,  0.28924497,  5.18534312]), -9.095668676318873, False, {})\n",
      "next_ [[-0.95725511  0.28924497  5.18534312]]\n",
      "[[0.28705302]]\n",
      "(array([-0.99981916,  0.01901721,  5.48839275]), -10.801092877106917, False, {})\n",
      "next_ [[-0.99981916  0.01901721  5.48839275]]\n",
      "[[0.0523202]]\n",
      "(array([-0.96718248, -0.25408277,  5.51835171]), -12.762726674141426, False, {})\n",
      "next_ [[-0.96718248 -0.25408277  5.51835171]]\n",
      "[[-0.51095891]]\n",
      "(array([-0.86998505, -0.4930781 ,  5.17450197]), -11.367721042626904, False, {})\n",
      "next_ [[-0.86998505 -0.4930781   5.17450197]]\n",
      "[[0.20367539]]\n",
      "(array([-0.72558366, -0.68813396,  4.86579601]), -9.573422653567617, False, {})\n",
      "next_ [[-0.72558366 -0.68813396  4.86579601]]\n",
      "[[-0.1561942]]\n",
      "(array([-0.56194916, -0.82717177,  4.30283728]), -8.04485163113235, False, {})\n",
      "next_ [[-0.56194916 -0.82717177  4.30283728]]\n",
      "[[-0.86479998]]\n",
      "(array([-0.41285769, -0.91079555,  3.42301846]), -6.552647569290704, False, {})\n",
      "next_ [[-0.41285769 -0.91079555  3.42301846]]\n",
      "[[0.76371074]]\n",
      "(array([-0.27360365, -0.96184252,  2.96903502]), -5.1595945774917915, False, {})\n",
      "next_ [[-0.27360365 -0.96184252  2.96903502]]\n",
      "[[0.01163508]]\n",
      "(array([-0.16383849, -0.98648718,  2.25114365]), -4.296377464806907, False, {})\n",
      "next_ [[-0.16383849 -0.98648718  2.25114365]]\n",
      "[[0.63893002]]\n",
      "(array([-0.07934911, -0.99684689,  1.70295728]), -3.519930360442419, False, {})\n",
      "next_ [[-0.07934911 -0.99684689  1.70295728]]\n",
      "[[-0.18045017]]\n",
      "(array([-0.03436649, -0.9994093 ,  0.90118706]), -3.013392160541922, False, {})\n",
      "next_ [[-0.03436649 -0.9994093   0.90118706]]\n",
      "[[0.42515206]]\n",
      "(array([-0.02041306, -0.99979163,  0.2791757 ]), -2.6585062401377364, False, {})\n",
      "next_ [[-0.02041306 -0.99979163  0.2791757 ]]\n",
      "[[-0.59702104]]\n",
      "(array([-0.05287852, -0.99860095, -0.64977433]), -2.5411714679776796, False, {})\n",
      "next_ [[-0.05287852 -0.99860095 -0.64977433]]\n",
      "[[-0.04177743]]\n",
      "(array([-0.12315266, -0.99238774, -1.41125827]), -2.6786277842131554, False, {})\n",
      "next_ [[-0.12315266 -0.99238774 -1.41125827]]\n",
      "[[-0.5192492]]\n",
      "(array([-0.23676255, -0.97156754, -2.31132384]), -3.070768668579347, False, {})\n",
      "next_ [[-0.23676255 -0.97156754 -2.31132384]]\n",
      "[[0.73035634]]\n",
      "(array([-0.37099191, -0.9286361 , -2.8208926 ]), -3.8118351279127176, False, {})\n",
      "next_ [[-0.37099191 -0.9286361  -2.8208926 ]]\n",
      "[[-0.62557673]]\n",
      "(array([-0.53569371, -0.84441237, -3.70504269]), -4.6032153517458765, False, {})\n",
      "next_ [[-0.53569371 -0.84441237 -3.70504269]]\n",
      "[[-0.48342064]]\n",
      "(array([-0.70999983, -0.70420184, -4.48337816]), -5.936700601563263, False, {})\n",
      "next_ [[-0.70999983 -0.70420184 -4.48337816]]\n",
      "[[-0.45531639]]\n",
      "(array([-0.86587869, -0.50025403, -5.14812446]), -7.58188640076115, False, {})\n",
      "next_ [[-0.86587869 -0.50025403 -5.14812446]]\n",
      "[[-0.7854141]]\n",
      "(array([-0.97229383, -0.23376207, -5.75893921]), -9.505142069148766, False, {})\n",
      "next_ [[-0.97229383 -0.23376207 -5.75893921]]\n",
      "[[0.05050466]]\n",
      "(array([-0.99819992,  0.05997429, -5.91910937]), -11.759335583267168, False, {})\n",
      "next_ [[-0.99819992  0.05997429 -5.91910937]]\n",
      "[[-0.30260712]]\n",
      "(array([-0.93650982,  0.35064134, -5.96491079]), -13.000101675594209, False, {})\n",
      "next_ [[-0.93650982  0.35064134 -5.96491079]]\n",
      "[[0.02285284]]\n",
      "(array([-0.80029485,  0.59960667, -5.69507393]), -11.30498199870134, False, {})\n",
      "next_ [[-0.80029485  0.59960667 -5.69507393]]\n",
      "[[-0.54563344]]\n",
      "(array([-0.61100843,  0.79162409, -5.40905896]), -9.487495181392056, False, {})\n",
      "next_ [[-0.61100843  0.79162409 -5.40905896]]\n",
      "[[0.21313031]]\n",
      "(array([-0.40754473,  0.91318525, -4.75140181]), -7.890537647185265, False, {})\n",
      "next_ [[-0.40754473  0.91318525 -4.75140181]]\n",
      "[[0.74487293]]\n",
      "(array([-0.22565099,  0.97420821, -3.84305099]), -6.22213069200326, False, {})\n",
      "next_ [[-0.22565099  0.97420821 -3.84305099]]\n",
      "[[0.81622082]]\n",
      "(array([-0.0841352 ,  0.99645435, -2.86752859]), -4.713838608699279, False, {})\n",
      "next_ [[-0.0841352   0.99645435 -2.86752859]]\n",
      "[[0.63602304]]\n",
      "(array([ 0.01223397,  0.99992516, -1.92938092]), -3.5630180717146955, False, {})\n",
      "next_ [[ 0.01223397  0.99992516 -1.92938092]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00758233]]\n",
      "(array([ 0.07103252,  0.997474  , -1.17716234]), -2.8013669847129683, False, {})\n",
      "next_ [[ 0.07103252  0.997474   -1.17716234]]\n",
      "[[0.61708683]]\n",
      "(array([ 0.08319266,  0.99653348, -0.2439308 ]), -2.389206207405214, False, {})\n",
      "next_ [[ 0.08319266  0.99653348 -0.2439308 ]]\n",
      "[[-0.97486001]]\n",
      "(array([0.07267424, 0.99735573, 0.21101131]), -2.2224298936630293, False, {})\n",
      "next_ [[0.07267424 0.99735573 0.21101131]]\n",
      "[[-0.20924109]]\n",
      "(array([0.02792194, 0.99961011, 0.89625578]), -2.2488053699638164, False, {})\n",
      "next_ [[0.02792194 0.99961011 0.89625578]]\n",
      "[[0.90094829]]\n",
      "(array([-0.06783469,  0.99769657,  1.91624785]), -2.46402443663616, False, {})\n",
      "next_ [[-0.06783469  0.99769657  1.91624785]]\n",
      "[[0.30008009]]\n",
      "(array([-0.2041683 ,  0.9789358 ,  2.75454431]), -3.052843227094364, False, {})\n",
      "next_ [[-0.2041683   0.9789358   2.75454431]]\n",
      "[[0.02737808]]\n",
      "(array([-0.37134949,  0.92849317,  3.49695958]), -3.914388203950183, False, {})\n",
      "next_ [[-0.37134949  0.92849317  3.49695958]]\n",
      "[[-0.46796465]]\n",
      "(array([-0.55062186,  0.83475479,  4.05294006]), -5.031157706815039, False, {})\n",
      "next_ [[-0.55062186  0.83475479  4.05294006]]\n",
      "[[0.59487975]]\n",
      "(array([-0.73521412,  0.67783493,  4.85747008]), -6.283356071225747, False, {})\n",
      "next_ [[-0.73521412  0.67783493  4.85747008]]\n",
      "[[0.15112087]]\n",
      "(array([-0.88963334,  0.45667551,  5.41118254]), -8.104141753945184, False, {})\n",
      "next_ [[-0.88963334  0.45667551  5.41118254]]\n",
      "[[-0.54856521]]\n",
      "(array([-0.98108666,  0.19356904,  5.58911961]), -10.043985214550885, False, {})\n",
      "next_ [[-0.98108666  0.19356904  5.58911961]]\n",
      "[[0.57917166]]\n",
      "(array([-0.99494371, -0.10043408,  5.90804789]), -11.808762176592268, False, {})\n",
      "next_ [[-0.99494371 -0.10043408  5.90804789]]\n",
      "[[-0.3956233]]\n",
      "(array([-0.92630736, -0.37676872,  5.71403534]), -12.738742899085365, False, {})\n",
      "next_ [[-0.92630736 -0.37676872  5.71403534]]\n",
      "[[0.15486872]]\n",
      "(array([-0.78986871, -0.61327597,  5.47791942]), -10.856723428605552, False, {})\n",
      "next_ [[-0.78986871 -0.61327597  5.47791942]]\n",
      "[[0.05277419]]\n",
      "(array([-0.61225157, -0.79066302,  5.0337947 ]), -9.158073641922389, False, {})\n",
      "next_ [[-0.61225157 -0.79066302  5.0337947 ]]\n"
     ]
    }
   ],
   "source": [
    "timestep = 0\n",
    "rewards = []\n",
    "for i_episode in range(1, 100):\n",
    "    st = time.time()\n",
    "    episode_r = 0\n",
    "    print('episode ',i_episode,' start at ',datetime.datetime.now())\n",
    "#     env_info = env.reset(train_mode=True)[brain_name]\n",
    "    \n",
    "#     state = env_info.vector_observations\n",
    "    state = np.array([env.reset()])\n",
    "    print(state)\n",
    "    score = np.zeros(num_agents)\n",
    "    for t in range(5000):\n",
    "        action = np.zeros((num_agents, action_dim)) # initialize multidimensional array actions of each agent\n",
    "        for i in range(num_agents):\n",
    "                state_i = torch.from_numpy(state[i,:]).float()\n",
    "                with torch.no_grad():\n",
    "#                     print('state ',i,state_i.shape)\n",
    "                    action[i,:] =  policy_net.get_action(state_i)\n",
    "        print(action)\n",
    "        env_info = env.step(action[0])#[brain_name]\n",
    "        print(env_info)\n",
    "#         next_state = np.array([np.transpose(env_info[0])])\n",
    "#         next_state = np.array([[env_info[0]]])\n",
    "#         reward = np.array([env_info[1]])                        # get reward (for each agent)\n",
    "#         done = np.array([env_info[2]])\n",
    "        next_state = np.array([env_info[0]])\n",
    "        print('next_', next_state)\n",
    "        reward = env_info[1]\n",
    "        done = env_info[2]\n",
    "        \n",
    "        score += reward\n",
    "#         print(env_info)\n",
    "#         print('add ', state, state.shape)\n",
    "#         print('done',done.shape)\n",
    "#         print(state, action, reward, next_state, done)\n",
    "#         print(state)\n",
    "        replay_buffer.add(state,action,[reward],next_state,done)\n",
    "        if len(replay_buffer) > batch_size:\n",
    "            policy_l = soft_q_update2(batch_size)\n",
    "            policy_loss.append(policy_l)\n",
    "        state = next_state\n",
    "        timestep += 1\n",
    "        episode_r += np.sum(reward)\n",
    "        \n",
    "        if timestep % 1000 == 0:\n",
    "            plot(timestep, rewards)\n",
    "        if np.any(done):\n",
    "            break\n",
    "    rewards.append(episode_r)\n",
    "    print(i_episode,time.time()-st)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(i_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "7.soft actor-critic.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "PyCharm (untitled)",
   "language": "python",
   "name": "pycharm-8c077bca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
